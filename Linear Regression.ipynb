{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f65d10ff-1898-4f35-be69-360ec24d985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55474948-cddd-4ce2-83bf-f963a635a8ac",
   "metadata": {},
   "source": [
    "## **--------------------------- Loading and Preparing data ---------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0104872-10ba-48a8-9c31-1f7700328575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208415d7-137f-4cd7-81ff-2466b1c94b11",
   "metadata": {},
   "source": [
    "## **------------------------------ spliting data (manual) ------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55de65ac-e91c-4738-8d1e-93c1a25ecc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X, y, test_size = 0.3):\n",
    "    num_samples = X.shape[0]\n",
    "    indices  =np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(num_samples * (1 - test_size))\n",
    "    train_indices, test_indices = indices[:split], indices[split:]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47295be5-bf9b-4b39-923a-0a7ced1573cf",
   "metadata": {},
   "source": [
    "## **--------------------------- spliting data (Scikit Learn) ----------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "973de400-0997-473a-8500-85cbeca63517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02acead-936a-4271-876c-ac798410ce6e",
   "metadata": {},
   "source": [
    "## **----------------------- Initializing Parameters (Scikit Learn) -----------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "572afcae-eae6-4de6-a1e9-0ab447e33948",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(X_train.shape[1]) # initialize weights\n",
    "b = 0.0 # initialize bias\n",
    "alpha = 0.001 # Learning Rate\n",
    "n_iter = 1000 # Number of Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d2ecc-8669-4a89-a5ab-78ed46cf983a",
   "metadata": {},
   "source": [
    "## **----------------------- Initializing Parameters (Scikit Learn) -----------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14152b66-19b7-4a14-83f2-043da6e4acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6cfff-7154-423f-890c-1a54eb05e4a7",
   "metadata": {},
   "source": [
    "## **------------------------------ Gradient Descent (manual) -----------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6fa3210d-6e97-4693-b7c3-431d861a47f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Weights = [-0.00294323 -0.1140971   0.31592312  0.16284284], Bias = -0.022110573110201957\n",
      "Iteration 2: Weights = [-0.00298219 -0.11413443  0.31599303  0.16289853], Bias = -0.022122032025421703\n",
      "Iteration 3: Weights = [-0.0030211  -0.11417165  0.31606279  0.16295414], Bias = -0.022133466682335148\n",
      "Iteration 4: Weights = [-0.00305995 -0.11420876  0.3161324   0.16300967], Bias = -0.02214487713161803\n",
      "Iteration 5: Weights = [-0.00309874 -0.11424576  0.31620186  0.16306514], Bias = -0.022156263423839716\n",
      "Iteration 6: Weights = [-0.00313747 -0.11428265  0.31627116  0.16312053], Bias = -0.022167625609463438\n",
      "Iteration 7: Weights = [-0.00317614 -0.11431943  0.31634032  0.16317585], Bias = -0.0221789637388465\n",
      "Iteration 8: Weights = [-0.00321475 -0.1143561   0.31640932  0.16323109], Bias = -0.022190277862240513\n",
      "Iteration 9: Weights = [-0.00325331 -0.11439265  0.31647818  0.16328627], Bias = -0.022201568029791608\n",
      "Iteration 10: Weights = [-0.00329181 -0.1144291   0.31654688  0.16334137], Bias = -0.022212834291540664\n",
      "Iteration 11: Weights = [-0.00333024 -0.11446544  0.31661544  0.16339639], Bias = -0.022224076697423528\n",
      "Iteration 12: Weights = [-0.00336863 -0.11450168  0.31668385  0.16345135], Bias = -0.02223529529727123\n",
      "Iteration 13: Weights = [-0.00340695 -0.1145378   0.31675211  0.16350623], Bias = -0.022246490140810208\n",
      "Iteration 14: Weights = [-0.00344521 -0.11457381  0.31682022  0.16356104], Bias = -0.02225766127766253\n",
      "Iteration 15: Weights = [-0.00348342 -0.11460972  0.31688818  0.16361578], Bias = -0.022268808757346104\n",
      "Iteration 16: Weights = [-0.00352157 -0.11464552  0.316956    0.16367045], Bias = -0.022279932629274905\n",
      "Iteration 17: Weights = [-0.00355967 -0.11468121  0.31702366  0.16372505], Bias = -0.022291032942759192\n",
      "Iteration 18: Weights = [-0.0035977  -0.11471679  0.31709118  0.16377957], Bias = -0.022302109747005725\n",
      "Iteration 19: Weights = [-0.00363568 -0.11475226  0.31715856  0.16383403], Bias = -0.022313163091117978\n",
      "Iteration 20: Weights = [-0.0036736  -0.11478763  0.31722579  0.16388841], Bias = -0.02232419302409636\n",
      "Iteration 21: Weights = [-0.00371147 -0.11482289  0.31729287  0.16394272], Bias = -0.02233519959483843\n",
      "Iteration 22: Weights = [-0.00374928 -0.11485805  0.3173598   0.16399696], Bias = -0.022346182852139115\n",
      "Iteration 23: Weights = [-0.00378703 -0.11489309  0.31742659  0.16405113], Bias = -0.02235714284469093\n",
      "Iteration 24: Weights = [-0.00382472 -0.11492803  0.31749324  0.16410524], Bias = -0.022368079621084173\n",
      "Iteration 25: Weights = [-0.00386236 -0.11496287  0.31755974  0.16415926], Bias = -0.022378993229807166\n",
      "Iteration 26: Weights = [-0.00389995 -0.1149976   0.31762609  0.16421322], Bias = -0.022389883719246453\n",
      "Iteration 27: Weights = [-0.00393747 -0.11503222  0.3176923   0.16426711], Bias = -0.022400751137687018\n",
      "Iteration 28: Weights = [-0.00397494 -0.11506674  0.31775837  0.16432093], Bias = -0.022411595533312494\n",
      "Iteration 29: Weights = [-0.00401236 -0.11510116  0.31782429  0.16437468], Bias = -0.022422416954205385\n",
      "Iteration 30: Weights = [-0.00404972 -0.11513546  0.31789007  0.16442836], Bias = -0.02243321544834727\n",
      "Iteration 31: Weights = [-0.00408702 -0.11516967  0.31795571  0.16448197], Bias = -0.022443991063619016\n",
      "Iteration 32: Weights = [-0.00412427 -0.11520377  0.3180212   0.16453552], Bias = -0.022454743847800995\n",
      "Iteration 33: Weights = [-0.00416146 -0.11523776  0.31808655  0.16458899], Bias = -0.022465473848573288\n",
      "Iteration 34: Weights = [-0.00419859 -0.11527166  0.31815176  0.16464239], Bias = -0.022476181113515896\n",
      "Iteration 35: Weights = [-0.00423568 -0.11530544  0.31821683  0.16469573], Bias = -0.02248686569010896\n",
      "Iteration 36: Weights = [-0.0042727  -0.11533913  0.31828175  0.16474899], Bias = -0.02249752762573296\n",
      "Iteration 37: Weights = [-0.00430967 -0.11537271  0.31834653  0.16480219], Bias = -0.022508166967668924\n",
      "Iteration 38: Weights = [-0.00434659 -0.11540619  0.31841118  0.16485532], Bias = -0.022518783763098644\n",
      "Iteration 39: Weights = [-0.00438345 -0.11543956  0.31847568  0.16490838], Bias = -0.02252937805910488\n",
      "Iteration 40: Weights = [-0.00442026 -0.11547283  0.31854004  0.16496137], Bias = -0.02253994990267157\n",
      "Iteration 41: Weights = [-0.00445701 -0.115506    0.31860426  0.16501429], Bias = -0.022550499340684035\n",
      "Iteration 42: Weights = [-0.00449371 -0.11553907  0.31866834  0.16506715], Bias = -0.022561026419929183\n",
      "Iteration 43: Weights = [-0.00453035 -0.11557204  0.31873228  0.16511994], Bias = -0.022571531187095727\n",
      "Iteration 44: Weights = [-0.00456694 -0.1156049   0.31879609  0.16517266], Bias = -0.02258201368877438\n",
      "Iteration 45: Weights = [-0.00460347 -0.11563766  0.31885975  0.16522531], Bias = -0.02259247397145806\n",
      "Iteration 46: Weights = [-0.00463996 -0.11567032  0.31892328  0.1652779 ], Bias = -0.022602912081542113\n",
      "Iteration 47: Weights = [-0.00467638 -0.11570288  0.31898666  0.16533042], Bias = -0.02261332806532449\n",
      "Iteration 48: Weights = [-0.00471276 -0.11573534  0.31904991  0.16538287], Bias = -0.022623721969005976\n",
      "Iteration 49: Weights = [-0.00474908 -0.1157677   0.31911302  0.16543525], Bias = -0.02263409383869038\n",
      "Iteration 50: Weights = [-0.00478534 -0.11579995  0.31917599  0.16548757], Bias = -0.022644443720384738\n",
      "Iteration 51: Weights = [-0.00482155 -0.11583211  0.31923883  0.16553982], Bias = -0.022654771659999535\n",
      "Iteration 52: Weights = [-0.00485771 -0.11586417  0.31930153  0.16559201], Bias = -0.02266507770334888\n",
      "Iteration 53: Weights = [-0.00489382 -0.11589613  0.31936409  0.16564413], Bias = -0.02267536189615073\n",
      "Iteration 54: Weights = [-0.00492987 -0.11592798  0.31942652  0.16569618], Bias = -0.02268562428402708\n",
      "Iteration 55: Weights = [-0.00496587 -0.11595974  0.31948881  0.16574816], Bias = -0.02269586491250417\n",
      "Iteration 56: Weights = [-0.00500182 -0.1159914   0.31955096  0.16580008], Bias = -0.02270608382701268\n",
      "Iteration 57: Weights = [-0.00503771 -0.11602296  0.31961298  0.16585194], Bias = -0.022716281072887937\n",
      "Iteration 58: Weights = [-0.00507355 -0.11605442  0.31967486  0.16590373], Bias = -0.022726456695370118\n",
      "Iteration 59: Weights = [-0.00510934 -0.11608578  0.31973661  0.16595545], Bias = -0.02273661073960444\n",
      "Iteration 60: Weights = [-0.00514508 -0.11611705  0.31979822  0.16600711], Bias = -0.02274674325064137\n",
      "Iteration 61: Weights = [-0.00518076 -0.11614821  0.3198597   0.1660587 ], Bias = -0.022756854273436808\n",
      "Iteration 62: Weights = [-0.0052164  -0.11617928  0.31992105  0.16611023], Bias = -0.022766943852852304\n",
      "Iteration 63: Weights = [-0.00525197 -0.11621025  0.31998226  0.16616169], Bias = -0.022777012033655245\n",
      "Iteration 64: Weights = [-0.0052875  -0.11624112  0.32004334  0.16621308], Bias = -0.022787058860519054\n",
      "Iteration 65: Weights = [-0.00532298 -0.1162719   0.32010428  0.16626442], Bias = -0.022797084378023393\n",
      "Iteration 66: Weights = [-0.0053584  -0.11630258  0.32016509  0.16631568], Bias = -0.022807088630654348\n",
      "Iteration 67: Weights = [-0.00539377 -0.11633316  0.32022577  0.16636689], Bias = -0.02281707166280464\n",
      "Iteration 68: Weights = [-0.00542909 -0.11636364  0.32028632  0.16641803], Bias = -0.022827033518773812\n",
      "Iteration 69: Weights = [-0.00546436 -0.11639403  0.32034673  0.1664691 ], Bias = -0.022836974242768426\n",
      "Iteration 70: Weights = [-0.00549958 -0.11642432  0.32040701  0.16652011], Bias = -0.02284689387890226\n",
      "Iteration 71: Weights = [-0.00553475 -0.11645452  0.32046716  0.16657106], Bias = -0.0228567924711965\n",
      "Iteration 72: Weights = [-0.00556986 -0.11648462  0.32052718  0.16662194], Bias = -0.022866670063579935\n",
      "Iteration 73: Weights = [-0.00560493 -0.11651462  0.32058707  0.16667276], Bias = -0.022876526699889155\n",
      "Iteration 74: Weights = [-0.00563994 -0.11654453  0.32064683  0.16672352], Bias = -0.02288636242386874\n",
      "Iteration 75: Weights = [-0.0056749  -0.11657434  0.32070645  0.16677421], Bias = -0.022896177279171454\n",
      "Iteration 76: Weights = [-0.00570981 -0.11660406  0.32076595  0.16682484], Bias = -0.02290597130935844\n",
      "Iteration 77: Weights = [-0.00574467 -0.11663368  0.32082532  0.1668754 ], Bias = -0.022915744557899406\n",
      "Iteration 78: Weights = [-0.00577948 -0.11666321  0.32088455  0.16692591], Bias = -0.02292549706817283\n",
      "Iteration 79: Weights = [-0.00581424 -0.11669264  0.32094366  0.16697634], Bias = -0.02293522888346614\n",
      "Iteration 80: Weights = [-0.00584895 -0.11672198  0.32100264  0.16702672], Bias = -0.022944940046975903\n",
      "Iteration 81: Weights = [-0.00588361 -0.11675123  0.32106149  0.16707704], Bias = -0.022954630601808027\n",
      "Iteration 82: Weights = [-0.00591822 -0.11678038  0.32112021  0.16712729], Bias = -0.022964300590977944\n",
      "Iteration 83: Weights = [-0.00595278 -0.11680944  0.3211788   0.16717748], Bias = -0.0229739500574108\n",
      "Iteration 84: Weights = [-0.00598729 -0.1168384   0.32123727  0.1672276 ], Bias = -0.022983579043941653\n",
      "Iteration 85: Weights = [-0.00602175 -0.11686728  0.32129561  0.16727767], Bias = -0.02299318759331564\n",
      "Iteration 86: Weights = [-0.00605616 -0.11689605  0.32135382  0.16732767], Bias = -0.0230027757481882\n",
      "Iteration 87: Weights = [-0.00609052 -0.11692474  0.3214119   0.16737761], Bias = -0.023012343551125226\n",
      "Iteration 88: Weights = [-0.00612483 -0.11695333  0.32146985  0.16742749], Bias = -0.023021891044603282\n",
      "Iteration 89: Weights = [-0.00615909 -0.11698183  0.32152768  0.16747731], Bias = -0.02303141827100977\n",
      "Iteration 90: Weights = [-0.0061933  -0.11701024  0.32158538  0.16752706], Bias = -0.023040925272643138\n",
      "Iteration 91: Weights = [-0.00622746 -0.11703856  0.32164296  0.16757676], Bias = -0.02305041209171304\n",
      "Iteration 92: Weights = [-0.00626157 -0.11706678  0.32170041  0.16762639], Bias = -0.023059878770340544\n",
      "Iteration 93: Weights = [-0.00629564 -0.11709491  0.32175773  0.16767597], Bias = -0.023069325350558313\n",
      "Iteration 94: Weights = [-0.00632965 -0.11712295  0.32181493  0.16772548], Bias = -0.02307875187431079\n",
      "Iteration 95: Weights = [-0.00636362 -0.1171509   0.32187201  0.16777493], Bias = -0.02308815838345437\n",
      "Iteration 96: Weights = [-0.00639754 -0.11717876  0.32192895  0.16782432], Bias = -0.02309754491975761\n",
      "Iteration 97: Weights = [-0.00643141 -0.11720653  0.32198578  0.16787365], Bias = -0.023106911524901397\n",
      "Iteration 98: Weights = [-0.00646523 -0.1172342   0.32204248  0.16792291], Bias = -0.02311625824047913\n",
      "Iteration 99: Weights = [-0.006499   -0.11726179  0.32209905  0.16797212], Bias = -0.02312558510799691\n",
      "Iteration 100: Weights = [-0.00653272 -0.11728928  0.32215551  0.16802127], Bias = -0.023134892168873728\n",
      "Iteration 101: Weights = [-0.0065664  -0.11731669  0.32221183  0.16807036], Bias = -0.02314417946444164\n",
      "Iteration 102: Weights = [-0.00660002 -0.11734401  0.32226804  0.16811939], Bias = -0.023153447035945945\n",
      "Iteration 103: Weights = [-0.0066336  -0.11737123  0.32232412  0.16816835], Bias = -0.02316269492454538\n",
      "Iteration 104: Weights = [-0.00666713 -0.11739837  0.32238008  0.16821726], Bias = -0.02317192317131229\n",
      "Iteration 105: Weights = [-0.00670062 -0.11742542  0.32243592  0.16826611], Bias = -0.023181131817232827\n",
      "Iteration 106: Weights = [-0.00673405 -0.11745237  0.32249163  0.1683149 ], Bias = -0.023190320903207103\n",
      "Iteration 107: Weights = [-0.00676744 -0.11747924  0.32254723  0.16836363], Bias = -0.02319949047004939\n",
      "Iteration 108: Weights = [-0.00680078 -0.11750602  0.3226027   0.1684123 ], Bias = -0.023208640558488307\n",
      "Iteration 109: Weights = [-0.00683408 -0.11753271  0.32265805  0.16846091], Bias = -0.023217771209166977\n",
      "Iteration 110: Weights = [-0.00686732 -0.11755932  0.32271327  0.16850946], Bias = -0.023226882462643227\n",
      "Iteration 111: Weights = [-0.00690052 -0.11758583  0.32276838  0.16855795], Bias = -0.02323597435938975\n",
      "Iteration 112: Weights = [-0.00693367 -0.11761226  0.32282337  0.16860639], Bias = -0.023245046939794303\n",
      "Iteration 113: Weights = [-0.00696678 -0.1176386   0.32287823  0.16865477], Bias = -0.02325410024415987\n",
      "Iteration 114: Weights = [-0.00699983 -0.11766485  0.32293298  0.16870308], Bias = -0.023263134312704842\n",
      "Iteration 115: Weights = [-0.00703284 -0.11769101  0.3229876   0.16875134], Bias = -0.023272149185563203\n",
      "Iteration 116: Weights = [-0.00706581 -0.11771709  0.32304211  0.16879954], Bias = -0.023281144902784694\n",
      "Iteration 117: Weights = [-0.00709873 -0.11774308  0.3230965   0.16884768], Bias = -0.023290121504335008\n",
      "Iteration 118: Weights = [-0.0071316  -0.11776898  0.32315076  0.16889577], Bias = -0.023299079030095947\n",
      "Iteration 119: Weights = [-0.00716442 -0.11779479  0.32320491  0.16894379], Bias = -0.02330801751986561\n",
      "Iteration 120: Weights = [-0.0071972  -0.11782052  0.32325894  0.16899176], Bias = -0.023316937013358567\n",
      "Iteration 121: Weights = [-0.00722993 -0.11784616  0.32331285  0.16903967], Bias = -0.023325837550206036\n",
      "Iteration 122: Weights = [-0.00726261 -0.11787172  0.32336664  0.16908753], Bias = -0.023334719169956046\n",
      "Iteration 123: Weights = [-0.00729525 -0.11789719  0.32342032  0.16913532], Bias = -0.02334358191207363\n",
      "Iteration 124: Weights = [-0.00732785 -0.11792257  0.32347388  0.16918306], Bias = -0.023352425815940984\n",
      "Iteration 125: Weights = [-0.00736039 -0.11794787  0.32352732  0.16923074], Bias = -0.02336125092085765\n",
      "Iteration 126: Weights = [-0.0073929  -0.11797309  0.32358064  0.16927837], Bias = -0.02337005726604069\n",
      "Iteration 127: Weights = [-0.00742535 -0.11799821  0.32363384  0.16932593], Bias = -0.023378844890624844\n",
      "Iteration 128: Weights = [-0.00745776 -0.11802326  0.32368693  0.16937344], Bias = -0.023387613833662724\n",
      "Iteration 129: Weights = [-0.00749013 -0.11804822  0.3237399   0.1694209 ], Bias = -0.023396364134124978\n",
      "Iteration 130: Weights = [-0.00752244 -0.11807309  0.32379276  0.16946829], Bias = -0.023405095830900453\n",
      "Iteration 131: Weights = [-0.00755472 -0.11809788  0.3238455   0.16951563], Bias = -0.023413808962796382\n",
      "Iteration 132: Weights = [-0.00758695 -0.11812258  0.32389812  0.16956292], Bias = -0.023422503568538547\n",
      "Iteration 133: Weights = [-0.00761913 -0.1181472   0.32395063  0.16961015], Bias = -0.023431179686771445\n",
      "Iteration 134: Weights = [-0.00765127 -0.11817174  0.32400302  0.16965732], Bias = -0.023439837356058472\n",
      "Iteration 135: Weights = [-0.00768336 -0.11819619  0.3240553   0.16970443], Bias = -0.023448476614882082\n",
      "Iteration 136: Weights = [-0.00771541 -0.11822056  0.32410747  0.16975149], Bias = -0.023457097501643962\n",
      "Iteration 137: Weights = [-0.00774741 -0.11824485  0.32415951  0.16979849], Bias = -0.0234657000546652\n",
      "Iteration 138: Weights = [-0.00777937 -0.11826905  0.32421145  0.16984544], Bias = -0.02347428431218645\n",
      "Iteration 139: Weights = [-0.00781129 -0.11829317  0.32426327  0.16989233], Bias = -0.023482850312368114\n",
      "Iteration 140: Weights = [-0.00784316 -0.1183172   0.32431498  0.16993917], Bias = -0.023491398093290497\n",
      "Iteration 141: Weights = [-0.00787498 -0.11834115  0.32436657  0.16998595], Bias = -0.023499927692953983\n",
      "Iteration 142: Weights = [-0.00790676 -0.11836503  0.32441805  0.17003268], Bias = -0.023508439149279196\n",
      "Iteration 143: Weights = [-0.0079385  -0.11838881  0.32446941  0.17007935], Bias = -0.023516932500107175\n",
      "Iteration 144: Weights = [-0.00797019 -0.11841252  0.32452067  0.17012596], Bias = -0.023525407783199535\n",
      "Iteration 145: Weights = [-0.00800184 -0.11843614  0.32457181  0.17017253], Bias = -0.023533865036238635\n",
      "Iteration 146: Weights = [-0.00803345 -0.11845969  0.32462284  0.17021903], Bias = -0.02354230429682775\n",
      "Iteration 147: Weights = [-0.00806501 -0.11848315  0.32467375  0.17026548], Bias = -0.02355072560249123\n",
      "Iteration 148: Weights = [-0.00809653 -0.11850652  0.32472456  0.17031188], Bias = -0.023559128990674662\n",
      "Iteration 149: Weights = [-0.008128   -0.11852982  0.32477525  0.17035822], Bias = -0.023567514498745057\n",
      "Iteration 150: Weights = [-0.00815943 -0.11855304  0.32482583  0.17040451], Bias = -0.023575882163990983\n",
      "Iteration 151: Weights = [-0.00819081 -0.11857617  0.3248763   0.17045074], Bias = -0.023584232023622757\n",
      "Iteration 152: Weights = [-0.00822216 -0.11859923  0.32492666  0.17049692], Bias = -0.023592564114772594\n",
      "Iteration 153: Weights = [-0.00825346 -0.1186222   0.32497691  0.17054305], Bias = -0.023600878474494776\n",
      "Iteration 154: Weights = [-0.00828471 -0.11864509  0.32502705  0.17058912], Bias = -0.023609175139765817\n",
      "Iteration 155: Weights = [-0.00831593 -0.11866791  0.32507707  0.17063514], Bias = -0.02361745414748462\n",
      "Iteration 156: Weights = [-0.0083471  -0.11869064  0.32512699  0.1706811 ], Bias = -0.023625715534472652\n",
      "Iteration 157: Weights = [-0.00837822 -0.11871329  0.3251768   0.17072701], Bias = -0.02363395933747409\n",
      "Iteration 158: Weights = [-0.00840931 -0.11873586  0.3252265   0.17077287], Bias = -0.023642185593155996\n",
      "Iteration 159: Weights = [-0.00844035 -0.11875836  0.32527608  0.17081867], Bias = -0.023650394338108477\n",
      "Iteration 160: Weights = [-0.00847135 -0.11878077  0.32532556  0.17086442], Bias = -0.023658585608844842\n",
      "Iteration 161: Weights = [-0.0085023  -0.11880311  0.32537493  0.17091012], Bias = -0.023666759441801764\n",
      "Iteration 162: Weights = [-0.00853322 -0.11882536  0.3254242   0.17095577], Bias = -0.02367491587333945\n",
      "Iteration 163: Weights = [-0.00856409 -0.11884754  0.32547335  0.17100136], Bias = -0.023683054939741786\n",
      "Iteration 164: Weights = [-0.00859492 -0.11886964  0.32552239  0.1710469 ], Bias = -0.02369117667721651\n",
      "Iteration 165: Weights = [-0.0086257  -0.11889165  0.32557133  0.17109238], Bias = -0.023699281121895368\n",
      "Iteration 166: Weights = [-0.00865645 -0.11891359  0.32562016  0.17113781], Bias = -0.02370736830983427\n",
      "Iteration 167: Weights = [-0.00868715 -0.11893546  0.32566888  0.17118319], Bias = -0.02371543827701345\n",
      "Iteration 168: Weights = [-0.00871781 -0.11895724  0.32571749  0.17122852], Bias = -0.02372349105933763\n",
      "Iteration 169: Weights = [-0.00874843 -0.11897895  0.325766    0.1712738 ], Bias = -0.02373152669263618\n",
      "Iteration 170: Weights = [-0.008779   -0.11900058  0.3258144   0.17131902], Bias = -0.023739545212663266\n",
      "Iteration 171: Weights = [-0.00880954 -0.11902213  0.32586269  0.17136419], Bias = -0.023747546655098012\n",
      "Iteration 172: Weights = [-0.00884003 -0.1190436   0.32591088  0.17140931], Bias = -0.023755531055544662\n",
      "Iteration 173: Weights = [-0.00887048 -0.119065    0.32595896  0.17145438], Bias = -0.023763498449532735\n",
      "Iteration 174: Weights = [-0.00890089 -0.11908631  0.32600694  0.1714994 ], Bias = -0.02377144887251718\n",
      "Iteration 175: Weights = [-0.00893126 -0.11910756  0.32605481  0.17154436], Bias = -0.02377938235987853\n",
      "Iteration 176: Weights = [-0.00896159 -0.11912872  0.32610257  0.17158928], Bias = -0.023787298946923073\n",
      "Iteration 177: Weights = [-0.00899187 -0.11914981  0.32615023  0.17163414], Bias = -0.023795198668882984\n",
      "Iteration 178: Weights = [-0.00902212 -0.11917082  0.32619778  0.17167895], Bias = -0.023803081560916498\n",
      "Iteration 179: Weights = [-0.00905232 -0.11919176  0.32624523  0.17172371], Bias = -0.023810947658108064\n",
      "Iteration 180: Weights = [-0.00908248 -0.11921262  0.32629257  0.17176841], Bias = -0.023818796995468492\n",
      "Iteration 181: Weights = [-0.0091126  -0.1192334   0.32633981  0.17181307], Bias = -0.023826629607935114\n",
      "Iteration 182: Weights = [-0.00914268 -0.11925411  0.32638695  0.17185768], Bias = -0.023834445530371937\n",
      "Iteration 183: Weights = [-0.00917272 -0.11927474  0.32643398  0.17190223], Bias = -0.023842244797569793\n",
      "Iteration 184: Weights = [-0.00920272 -0.1192953   0.3264809   0.17194674], Bias = -0.023850027444246504\n",
      "Iteration 185: Weights = [-0.00923268 -0.11931578  0.32652773  0.17199119], Bias = -0.023857793505047017\n",
      "Iteration 186: Weights = [-0.0092626  -0.11933619  0.32657445  0.17203559], Bias = -0.02386554301454357\n",
      "Iteration 187: Weights = [-0.00929248 -0.11935652  0.32662106  0.17207995], Bias = -0.02387327600723585\n",
      "Iteration 188: Weights = [-0.00932231 -0.11937677  0.32666758  0.17212425], Bias = -0.023880992517551127\n",
      "Iteration 189: Weights = [-0.00935211 -0.11939695  0.32671399  0.1721685 ], Bias = -0.02388869257984442\n",
      "Iteration 190: Weights = [-0.00938187 -0.11941706  0.3267603   0.1722127 ], Bias = -0.02389637622839864\n",
      "Iteration 191: Weights = [-0.00941158 -0.11943709  0.3268065   0.17225686], Bias = -0.02390404349742476\n",
      "Iteration 192: Weights = [-0.00944126 -0.11945705  0.32685261  0.17230096], Bias = -0.02391169442106194\n",
      "Iteration 193: Weights = [-0.0094709  -0.11947694  0.32689861  0.17234501], Bias = -0.02391932903337769\n",
      "Iteration 194: Weights = [-0.0095005  -0.11949675  0.32694451  0.17238901], Bias = -0.023926947368368024\n",
      "Iteration 195: Weights = [-0.00953005 -0.11951648  0.32699031  0.17243297], Bias = -0.02393454945995761\n",
      "Iteration 196: Weights = [-0.00955957 -0.11953615  0.32703601  0.17247687], Bias = -0.023942135341999907\n",
      "Iteration 197: Weights = [-0.00958905 -0.11955574  0.32708161  0.17252073], Bias = -0.023949705048277332\n",
      "Iteration 198: Weights = [-0.00961849 -0.11957525  0.3271271   0.17256453], Bias = -0.0239572586125014\n",
      "Iteration 199: Weights = [-0.00964789 -0.1195947   0.3271725   0.17260829], Bias = -0.02396479606831287\n",
      "Iteration 200: Weights = [-0.00967725 -0.11961407  0.32721779  0.172652  ], Bias = -0.023972317449281896\n",
      "Iteration 201: Weights = [-0.00970657 -0.11963337  0.32726299  0.17269565], Bias = -0.023979822788908187\n",
      "Iteration 202: Weights = [-0.00973585 -0.11965259  0.32730809  0.17273926], Bias = -0.02398731212062113\n",
      "Iteration 203: Weights = [-0.00976509 -0.11967174  0.32735308  0.17278282], Bias = -0.023994785477779966\n",
      "Iteration 204: Weights = [-0.00979429 -0.11969082  0.32739798  0.17282634], Bias = -0.024002242893673913\n",
      "Iteration 205: Weights = [-0.00982346 -0.11970983  0.32744277  0.1728698 ], Bias = -0.024009684401522326\n",
      "Iteration 206: Weights = [-0.00985258 -0.11972877  0.32748747  0.17291321], Bias = -0.024017110034474844\n",
      "Iteration 207: Weights = [-0.00988167 -0.11974763  0.32753207  0.17295658], Bias = -0.02402451982561153\n",
      "Iteration 208: Weights = [-0.00991071 -0.11976643  0.32757657  0.1729999 ], Bias = -0.024031913807943027\n",
      "Iteration 209: Weights = [-0.00993972 -0.11978515  0.32762097  0.17304317], Bias = -0.024039292014410685\n",
      "Iteration 210: Weights = [-0.00996869 -0.1198038   0.32766528  0.17308639], Bias = -0.024046654477886727\n",
      "Iteration 211: Weights = [-0.00999763 -0.11982237  0.32770948  0.17312957], Bias = -0.024054001231174387\n",
      "Iteration 212: Weights = [-0.01002652 -0.11984088  0.32775359  0.17317269], Bias = -0.024061332307008052\n",
      "Iteration 213: Weights = [-0.01005538 -0.11985932  0.3277976   0.17321577], Bias = -0.024068647738053405\n",
      "Iteration 214: Weights = [-0.01008419 -0.11987768  0.32784151  0.1732588 ], Bias = -0.024075947556907572\n",
      "Iteration 215: Weights = [-0.01011297 -0.11989598  0.32788533  0.17330178], Bias = -0.024083231796099273\n",
      "Iteration 216: Weights = [-0.01014171 -0.1199142   0.32792904  0.17334472], Bias = -0.024090500488088952\n",
      "Iteration 217: Weights = [-0.01017041 -0.11993236  0.32797267  0.17338761], Bias = -0.024097753665268933\n",
      "Iteration 218: Weights = [-0.01019908 -0.11995044  0.32801619  0.17343045], Bias = -0.02410499135996355\n",
      "Iteration 219: Weights = [-0.01022771 -0.11996845  0.32805962  0.17347324], Bias = -0.02411221360442931\n",
      "Iteration 220: Weights = [-0.0102563  -0.1199864   0.32810295  0.17351599], Bias = -0.024119420430855004\n",
      "Iteration 221: Weights = [-0.01028485 -0.12000427  0.32814619  0.17355869], Bias = -0.02412661187136188\n",
      "Iteration 222: Weights = [-0.01031336 -0.12002208  0.32818933  0.17360134], Bias = -0.024133787958003774\n",
      "Iteration 223: Weights = [-0.01034184 -0.12003981  0.32823237  0.17364395], Bias = -0.024140948722767237\n",
      "Iteration 224: Weights = [-0.01037028 -0.12005748  0.32827532  0.17368651], Bias = -0.024148094197571704\n",
      "Iteration 225: Weights = [-0.01039868 -0.12007508  0.32831817  0.17372902], Bias = -0.02415522441426961\n",
      "Iteration 226: Weights = [-0.01042704 -0.1200926   0.32836093  0.17377149], Bias = -0.02416233940464655\n",
      "Iteration 227: Weights = [-0.01045537 -0.12011006  0.3284036   0.17381391], Bias = -0.0241694392004214\n",
      "Iteration 228: Weights = [-0.01048366 -0.12012745  0.32844616  0.17385628], Bias = -0.02417652383324647\n",
      "Iteration 229: Weights = [-0.01051191 -0.12014477  0.32848864  0.17389861], Bias = -0.024183593334707643\n",
      "Iteration 230: Weights = [-0.01054013 -0.12016203  0.32853102  0.17394089], Bias = -0.024190647736324514\n",
      "Iteration 231: Weights = [-0.0105683  -0.12017921  0.32857331  0.17398312], Bias = -0.02419768706955052\n",
      "Iteration 232: Weights = [-0.01059645 -0.12019633  0.3286155   0.17402531], Bias = -0.024204711365773096\n",
      "Iteration 233: Weights = [-0.01062455 -0.12021338  0.3286576   0.17406745], Bias = -0.024211720656313798\n",
      "Iteration 234: Weights = [-0.01065262 -0.12023036  0.3286996   0.17410955], Bias = -0.024218714972428446\n",
      "Iteration 235: Weights = [-0.01068065 -0.12024727  0.32874152  0.1741516 ], Bias = -0.024225694345307268\n",
      "Iteration 236: Weights = [-0.01070865 -0.12026412  0.32878334  0.17419361], Bias = -0.024232658806075027\n",
      "Iteration 237: Weights = [-0.0107366  -0.1202809   0.32882506  0.17423557], Bias = -0.02423960838579117\n",
      "Iteration 238: Weights = [-0.01076453 -0.12029761  0.3288667   0.17427749], Bias = -0.024246543115449957\n",
      "Iteration 239: Weights = [-0.01079241 -0.12031425  0.32890824  0.17431936], Bias = -0.0242534630259806\n",
      "Iteration 240: Weights = [-0.01082026 -0.12033083  0.32894969  0.17436118], Bias = -0.024260368148247398\n",
      "Iteration 241: Weights = [-0.01084808 -0.12034734  0.32899104  0.17440296], Bias = -0.024267258513049884\n",
      "Iteration 242: Weights = [-0.01087585 -0.12036378  0.32903231  0.1744447 ], Bias = -0.02427413415112294\n",
      "Iteration 243: Weights = [-0.01090359 -0.12038016  0.32907348  0.17448639], Bias = -0.02428099509313695\n",
      "Iteration 244: Weights = [-0.0109313  -0.12039647  0.32911456  0.17452803], Bias = -0.024287841369697933\n",
      "Iteration 245: Weights = [-0.01095897 -0.12041272  0.32915555  0.17456963], Bias = -0.024294673011347672\n",
      "Iteration 246: Weights = [-0.0109866  -0.1204289   0.32919645  0.17461119], Bias = -0.024301490048563853\n",
      "Iteration 247: Weights = [-0.0110142  -0.12044501  0.32923726  0.1746527 ], Bias = -0.0243082925117602\n",
      "Iteration 248: Weights = [-0.01104176 -0.12046106  0.32927798  0.17469416], Bias = -0.024315080431286603\n",
      "Iteration 249: Weights = [-0.01106929 -0.12047704  0.32931861  0.17473559], Bias = -0.024321853837429266\n",
      "Iteration 250: Weights = [-0.01109678 -0.12049295  0.32935914  0.17477696], Bias = -0.024328612760410824\n",
      "Iteration 251: Weights = [-0.01112424 -0.1205088   0.32939959  0.1748183 ], Bias = -0.02433535723039049\n",
      "Iteration 252: Weights = [-0.01115166 -0.12052459  0.32943995  0.17485959], Bias = -0.02434208727746418\n",
      "Iteration 253: Weights = [-0.01117904 -0.12054031  0.32948021  0.17490083], Bias = -0.02434880293166464\n",
      "Iteration 254: Weights = [-0.01120639 -0.12055596  0.32952039  0.17494203], Bias = -0.0243555042229616\n",
      "Iteration 255: Weights = [-0.0112337  -0.12057155  0.32956048  0.17498319], Bias = -0.02436219118126189\n",
      "Iteration 256: Weights = [-0.01126098 -0.12058708  0.32960048  0.1750243 ], Bias = -0.024368863836409568\n",
      "Iteration 257: Weights = [-0.01128823 -0.12060254  0.32964039  0.17506538], Bias = -0.024375522218186067\n",
      "Iteration 258: Weights = [-0.01131544 -0.12061794  0.32968021  0.1751064 ], Bias = -0.024382166356310315\n",
      "Iteration 259: Weights = [-0.01134261 -0.12063327  0.32971994  0.17514739], Bias = -0.02438879628043887\n",
      "Iteration 260: Weights = [-0.01136975 -0.12064854  0.32975958  0.17518833], Bias = -0.02439541202016605\n",
      "Iteration 261: Weights = [-0.01139686 -0.12066374  0.32979914  0.17522922], Bias = -0.024402013605024066\n",
      "Iteration 262: Weights = [-0.01142393 -0.12067888  0.32983861  0.17527007], Bias = -0.02440860106448315\n",
      "Iteration 263: Weights = [-0.01145096 -0.12069396  0.32987798  0.17531089], Bias = -0.024415174427951682\n",
      "Iteration 264: Weights = [-0.01147796 -0.12070897  0.32991728  0.17535165], Bias = -0.02442173372477633\n",
      "Iteration 265: Weights = [-0.01150493 -0.12072392  0.32995648  0.17539238], Bias = -0.02442827898424217\n",
      "Iteration 266: Weights = [-0.01153186 -0.1207388   0.3299956   0.17543306], Bias = -0.024434810235572823\n",
      "Iteration 267: Weights = [-0.01155876 -0.12075363  0.33003463  0.1754737 ], Bias = -0.024441327507930568\n",
      "Iteration 268: Weights = [-0.01158562 -0.12076839  0.33007357  0.17551429], Bias = -0.024447830830416493\n",
      "Iteration 269: Weights = [-0.01161245 -0.12078308  0.33011242  0.17555485], Bias = -0.02445432023207061\n",
      "Iteration 270: Weights = [-0.01163925 -0.12079772  0.33015119  0.17559536], Bias = -0.024460795741871984\n",
      "Iteration 271: Weights = [-0.01166601 -0.12081229  0.33018988  0.17563582], Bias = -0.024467257388738867\n",
      "Iteration 272: Weights = [-0.01169274 -0.1208268   0.33022847  0.17567625], Bias = -0.024473705201528816\n",
      "Iteration 273: Weights = [-0.01171943 -0.12084125  0.33026698  0.17571663], Bias = -0.02448013920903883\n",
      "Iteration 274: Weights = [-0.01174609 -0.12085563  0.33030541  0.17575698], Bias = -0.02448655944000547\n",
      "Iteration 275: Weights = [-0.01177271 -0.12086995  0.33034374  0.17579728], Bias = -0.024492965923104994\n",
      "Iteration 276: Weights = [-0.01179931 -0.12088421  0.330382    0.17583753], Bias = -0.024499358686953476\n",
      "Iteration 277: Weights = [-0.01182586 -0.12089841  0.33042016  0.17587775], Bias = -0.024505737760106932\n",
      "Iteration 278: Weights = [-0.01185239 -0.12091255  0.33045825  0.17591792], Bias = -0.024512103171061454\n",
      "Iteration 279: Weights = [-0.01187888 -0.12092662  0.33049624  0.17595805], Bias = -0.024518454948253325\n",
      "Iteration 280: Weights = [-0.01190534 -0.12094064  0.33053416  0.17599814], Bias = -0.02452479312005916\n",
      "Iteration 281: Weights = [-0.01193176 -0.12095459  0.33057198  0.17603819], Bias = -0.024531117714796012\n",
      "Iteration 282: Weights = [-0.01195815 -0.12096848  0.33060973  0.1760782 ], Bias = -0.02453742876072151\n",
      "Iteration 283: Weights = [-0.01198451 -0.12098231  0.33064739  0.17611817], Bias = -0.024543726286033983\n",
      "Iteration 284: Weights = [-0.01201084 -0.12099608  0.33068496  0.17615809], Bias = -0.024550010318872578\n",
      "Iteration 285: Weights = [-0.01203713 -0.12100979  0.33072245  0.17619797], Bias = -0.024556280887317393\n",
      "Iteration 286: Weights = [-0.01206339 -0.12102344  0.33075986  0.17623782], Bias = -0.024562538019389592\n",
      "Iteration 287: Weights = [-0.01208961 -0.12103702  0.33079718  0.17627762], Bias = -0.024568781743051535\n",
      "Iteration 288: Weights = [-0.01211581 -0.12105055  0.33083442  0.17631738], Bias = -0.024575012086206896\n",
      "Iteration 289: Weights = [-0.01214197 -0.12106402  0.33087158  0.1763571 ], Bias = -0.024581229076700795\n",
      "Iteration 290: Weights = [-0.0121681  -0.12107742  0.33090865  0.17639677], Bias = -0.024587432742319913\n",
      "Iteration 291: Weights = [-0.01219419 -0.12109077  0.33094564  0.17643641], Bias = -0.024593623110792617\n",
      "Iteration 292: Weights = [-0.01222025 -0.12110406  0.33098255  0.17647601], Bias = -0.02459980020978908\n",
      "Iteration 293: Weights = [-0.01224628 -0.12111728  0.33101938  0.17651557], Bias = -0.02460596406692141\n",
      "Iteration 294: Weights = [-0.01227228 -0.12113045  0.33105612  0.17655508], Bias = -0.024612114709743768\n",
      "Iteration 295: Weights = [-0.01229824 -0.12114356  0.33109278  0.17659456], Bias = -0.024618252165752485\n",
      "Iteration 296: Weights = [-0.01232418 -0.12115661  0.33112936  0.17663399], Bias = -0.02462437646238619\n",
      "Iteration 297: Weights = [-0.01235008 -0.1211696   0.33116586  0.17667339], Bias = -0.024630487627025927\n",
      "Iteration 298: Weights = [-0.01237594 -0.12118253  0.33120227  0.17671274], Bias = -0.024636585686995283\n",
      "Iteration 299: Weights = [-0.01240178 -0.1211954   0.33123861  0.17675206], Bias = -0.024642670669560496\n",
      "Iteration 300: Weights = [-0.01242758 -0.12120821  0.33127486  0.17679133], Bias = -0.02464874260193059\n",
      "Iteration 301: Weights = [-0.01245335 -0.12122096  0.33131103  0.17683057], Bias = -0.024654801511257485\n",
      "Iteration 302: Weights = [-0.01247909 -0.12123366  0.33134712  0.17686976], Bias = -0.024660847424636118\n",
      "Iteration 303: Weights = [-0.0125048  -0.1212463   0.33138313  0.17690892], Bias = -0.024666880369104565\n",
      "Iteration 304: Weights = [-0.01253048 -0.12125887  0.33141906  0.17694803], Bias = -0.024672900371644164\n",
      "Iteration 305: Weights = [-0.01255612 -0.12127139  0.33145491  0.17698711], Bias = -0.024678907459179625\n",
      "Iteration 306: Weights = [-0.01258173 -0.12128386  0.33149068  0.17702614], Bias = -0.024684901658579155\n",
      "Iteration 307: Weights = [-0.01260732 -0.12129626  0.33152636  0.17706514], Bias = -0.024690882996654576\n",
      "Iteration 308: Weights = [-0.01263286 -0.12130861  0.33156197  0.1771041 ], Bias = -0.02469685150016144\n",
      "Iteration 309: Weights = [-0.01265838 -0.12132089  0.3315975   0.17714302], Bias = -0.024702807195799155\n",
      "Iteration 310: Weights = [-0.01268387 -0.12133312  0.33163295  0.1771819 ], Bias = -0.024708750110211095\n",
      "Iteration 311: Weights = [-0.01270932 -0.1213453   0.33166832  0.17722074], Bias = -0.02471468026998472\n",
      "Iteration 312: Weights = [-0.01273475 -0.12135741  0.33170361  0.17725954], Bias = -0.024720597701651695\n",
      "Iteration 313: Weights = [-0.01276014 -0.12136947  0.33173882  0.1772983 ], Bias = -0.024726502431688002\n",
      "Iteration 314: Weights = [-0.0127855  -0.12138147  0.33177395  0.17733702], Bias = -0.024732394486514066\n",
      "Iteration 315: Weights = [-0.01281083 -0.12139342  0.331809    0.17737571], Bias = -0.024738273892494868\n",
      "Iteration 316: Weights = [-0.01283613 -0.12140531  0.33184397  0.17741435], Bias = -0.02474414067594005\n",
      "Iteration 317: Weights = [-0.0128614  -0.12141714  0.33187887  0.17745296], Bias = -0.024749994863104054\n",
      "Iteration 318: Weights = [-0.01288663 -0.12142891  0.33191369  0.17749153], Bias = -0.02475583648018621\n",
      "Iteration 319: Weights = [-0.01291184 -0.12144063  0.33194842  0.17753006], Bias = -0.02476166555333088\n",
      "Iteration 320: Weights = [-0.01293702 -0.12145229  0.33198309  0.17756855], Bias = -0.024767482108627555\n",
      "Iteration 321: Weights = [-0.01296216 -0.1214639   0.33201767  0.17760701], Bias = -0.024773286172110973\n",
      "Iteration 322: Weights = [-0.01298727 -0.12147545  0.33205217  0.17764542], Bias = -0.02477907776976124\n",
      "Iteration 323: Weights = [-0.01301236 -0.12148694  0.3320866   0.1776838 ], Bias = -0.02478485692750394\n",
      "Iteration 324: Weights = [-0.01303741 -0.12149838  0.33212095  0.17772214], Bias = -0.024790623671210245\n",
      "Iteration 325: Weights = [-0.01306243 -0.12150976  0.33215522  0.17776044], Bias = -0.02479637802669704\n",
      "Iteration 326: Weights = [-0.01308742 -0.12152108  0.33218942  0.1777987 ], Bias = -0.024802120019727033\n",
      "Iteration 327: Weights = [-0.01311239 -0.12153235  0.33222354  0.17783693], Bias = -0.024807849676008863\n",
      "Iteration 328: Weights = [-0.01313732 -0.12154357  0.33225758  0.17787511], Bias = -0.02481356702119722\n",
      "Iteration 329: Weights = [-0.01316222 -0.12155473  0.33229155  0.17791326], Bias = -0.024819272080892952\n",
      "Iteration 330: Weights = [-0.01318709 -0.12156583  0.33232544  0.17795137], Bias = -0.02482496488064319\n",
      "Iteration 331: Weights = [-0.01321193 -0.12157688  0.33235925  0.17798945], Bias = -0.024830645445941442\n",
      "Iteration 332: Weights = [-0.01323674 -0.12158788  0.33239299  0.17802749], Bias = -0.024836313802227727\n",
      "Iteration 333: Weights = [-0.01326152 -0.12159882  0.33242665  0.17806549], Bias = -0.02484196997488867\n",
      "Iteration 334: Weights = [-0.01328627 -0.1216097   0.33246024  0.17810345], Bias = -0.024847613989257628\n",
      "Iteration 335: Weights = [-0.01331099 -0.12162053  0.33249375  0.17814137], Bias = -0.024853245870614785\n",
      "Iteration 336: Weights = [-0.01333568 -0.12163131  0.33252718  0.17817926], Bias = -0.024858865644187277\n",
      "Iteration 337: Weights = [-0.01336034 -0.12164203  0.33256054  0.17821711], Bias = -0.024864473335149302\n",
      "Iteration 338: Weights = [-0.01338497 -0.1216527   0.33259383  0.17825493], Bias = -0.024870068968622226\n",
      "Iteration 339: Weights = [-0.01340958 -0.12166331  0.33262703  0.1782927 ], Bias = -0.024875652569674698\n",
      "Iteration 340: Weights = [-0.01343415 -0.12167387  0.33266017  0.17833044], Bias = -0.02488122416332276\n",
      "Iteration 341: Weights = [-0.01345869 -0.12168437  0.33269323  0.17836815], Bias = -0.02488678377452995\n",
      "Iteration 342: Weights = [-0.0134832  -0.12169482  0.33272621  0.17840581], Bias = -0.02489233142820743\n",
      "Iteration 343: Weights = [-0.01350769 -0.12170522  0.33275913  0.17844344], Bias = -0.024897867149214083\n",
      "Iteration 344: Weights = [-0.01353214 -0.12171557  0.33279196  0.17848104], Bias = -0.024903390962356615\n",
      "Iteration 345: Weights = [-0.01355657 -0.12172586  0.33282473  0.17851859], Bias = -0.024908902892389683\n",
      "Iteration 346: Weights = [-0.01358096 -0.1217361   0.33285741  0.17855611], Bias = -0.02491440296401599\n",
      "Iteration 347: Weights = [-0.01360533 -0.12174628  0.33289003  0.1785936 ], Bias = -0.024919891201886406\n",
      "Iteration 348: Weights = [-0.01362967 -0.12175641  0.33292257  0.17863104], Bias = -0.024925367630600066\n",
      "Iteration 349: Weights = [-0.01365398 -0.12176649  0.33295504  0.17866846], Bias = -0.024930832274704485\n",
      "Iteration 350: Weights = [-0.01367826 -0.12177652  0.33298743  0.17870583], Bias = -0.02493628515869566\n",
      "Iteration 351: Weights = [-0.01370251 -0.12178649  0.33301976  0.17874317], Bias = -0.02494172630701819\n",
      "Iteration 352: Weights = [-0.01372673 -0.12179641  0.33305201  0.17878047], Bias = -0.02494715574406537\n",
      "Iteration 353: Weights = [-0.01375092 -0.12180628  0.33308418  0.17881774], Bias = -0.024952573494179307\n",
      "Iteration 354: Weights = [-0.01377509 -0.12181609  0.33311629  0.17885497], Bias = -0.024957979581651028\n",
      "Iteration 355: Weights = [-0.01379922 -0.12182585  0.33314832  0.17889217], Bias = -0.02496337403072058\n",
      "Iteration 356: Weights = [-0.01382333 -0.12183557  0.33318028  0.17892933], Bias = -0.024968756865577143\n",
      "Iteration 357: Weights = [-0.01384741 -0.12184522  0.33321216  0.17896645], Bias = -0.02497412811035914\n",
      "Iteration 358: Weights = [-0.01387146 -0.12185483  0.33324398  0.17900354], Bias = -0.024979487789154337\n",
      "Iteration 359: Weights = [-0.01389548 -0.12186439  0.33327572  0.1790406 ], Bias = -0.02498483592599995\n",
      "Iteration 360: Weights = [-0.01391947 -0.12187389  0.33330739  0.17907761], Bias = -0.024990172544882755\n",
      "Iteration 361: Weights = [-0.01394343 -0.12188334  0.33333899  0.1791146 ], Bias = -0.024995497669739186\n",
      "Iteration 362: Weights = [-0.01396737 -0.12189274  0.33337052  0.17915154], Bias = -0.025000811324455453\n",
      "Iteration 363: Weights = [-0.01399128 -0.12190209  0.33340198  0.17918846], Bias = -0.02500611353286764\n",
      "Iteration 364: Weights = [-0.01401516 -0.12191139  0.33343336  0.17922533], Bias = -0.025011404318761806\n",
      "Iteration 365: Weights = [-0.01403901 -0.12192064  0.33346468  0.17926218], Bias = -0.0250166837058741\n",
      "Iteration 366: Weights = [-0.01406283 -0.12192983  0.33349592  0.17929898], Bias = -0.025021951717890855\n",
      "Iteration 367: Weights = [-0.01408663 -0.12193898  0.33352709  0.17933576], Bias = -0.025027208378448705\n",
      "Iteration 368: Weights = [-0.0141104  -0.12194807  0.3335582   0.17937249], Bias = -0.02503245371113468\n",
      "Iteration 369: Weights = [-0.01413414 -0.12195711  0.33358923  0.1794092 ], Bias = -0.02503768773948631\n",
      "Iteration 370: Weights = [-0.01415785 -0.1219661   0.33362019  0.17944587], Bias = -0.025042910486991733\n",
      "Iteration 371: Weights = [-0.01418153 -0.12197505  0.33365108  0.1794825 ], Bias = -0.0250481219770898\n",
      "Iteration 372: Weights = [-0.01420519 -0.12198394  0.3336819   0.1795191 ], Bias = -0.025053322233170177\n",
      "Iteration 373: Weights = [-0.01422882 -0.12199278  0.33371266  0.17955566], Bias = -0.02505851127857344\n",
      "Iteration 374: Weights = [-0.01425242 -0.12200157  0.33374334  0.17959219], Bias = -0.02506368913659119\n",
      "Iteration 375: Weights = [-0.01427599 -0.12201031  0.33377395  0.17962869], Bias = -0.02506885583046615\n",
      "Iteration 376: Weights = [-0.01429954 -0.122019    0.3338045   0.17966515], Bias = -0.025074011383392273\n",
      "Iteration 377: Weights = [-0.01432306 -0.12202764  0.33383497  0.17970158], Bias = -0.025079155818514828\n",
      "Iteration 378: Weights = [-0.01434655 -0.12203623  0.33386538  0.17973797], Bias = -0.025084289158930528\n",
      "Iteration 379: Weights = [-0.01437001 -0.12204478  0.33389571  0.17977433], Bias = -0.02508941142768761\n",
      "Iteration 380: Weights = [-0.01439345 -0.12205327  0.33392598  0.17981065], Bias = -0.025094522647785947\n",
      "Iteration 381: Weights = [-0.01441686 -0.12206171  0.33395618  0.17984695], Bias = -0.02509962284217715\n",
      "Iteration 382: Weights = [-0.01444024 -0.1220701   0.33398631  0.1798832 ], Bias = -0.02510471203376466\n",
      "Iteration 383: Weights = [-0.0144636  -0.12207845  0.33401637  0.17991943], Bias = -0.025109790245403864\n",
      "Iteration 384: Weights = [-0.01448693 -0.12208674  0.33404637  0.17995562], Bias = -0.02511485749990218\n",
      "Iteration 385: Weights = [-0.01451023 -0.12209499  0.33407629  0.17999177], Bias = -0.02511991382001917\n",
      "Iteration 386: Weights = [-0.0145335  -0.12210319  0.33410615  0.18002789], Bias = -0.02512495922846664\n",
      "Iteration 387: Weights = [-0.01455675 -0.12211134  0.33413594  0.18006398], Bias = -0.025129993747908724\n",
      "Iteration 388: Weights = [-0.01457997 -0.12211944  0.33416566  0.18010004], Bias = -0.02513501740096201\n",
      "Iteration 389: Weights = [-0.01460316 -0.12212749  0.33419532  0.18013606], Bias = -0.025140030210195615\n",
      "Iteration 390: Weights = [-0.01462633 -0.12213549  0.33422491  0.18017205], Bias = -0.0251450321981313\n",
      "Iteration 391: Weights = [-0.01464947 -0.12214344  0.33425443  0.18020801], Bias = -0.025150023387243568\n",
      "Iteration 392: Weights = [-0.01467258 -0.12215135  0.33428388  0.18024393], Bias = -0.025155003799959757\n",
      "Iteration 393: Weights = [-0.01469567 -0.12215921  0.33431327  0.18027982], Bias = -0.025159973458660143\n",
      "Iteration 394: Weights = [-0.01471873 -0.12216702  0.33434259  0.18031567], Bias = -0.02516493238567804\n",
      "Iteration 395: Weights = [-0.01474177 -0.12217478  0.33437184  0.1803515 ], Bias = -0.02516988060329989\n",
      "Iteration 396: Weights = [-0.01476477 -0.12218249  0.33440103  0.18038729], Bias = -0.02517481813376538\n",
      "Iteration 397: Weights = [-0.01478775 -0.12219016  0.33443015  0.18042305], Bias = -0.025179744999267516\n",
      "Iteration 398: Weights = [-0.01481071 -0.12219778  0.3344592   0.18045877], Bias = -0.02518466122195274\n",
      "Iteration 399: Weights = [-0.01483364 -0.12220535  0.33448819  0.18049446], Bias = -0.02518956682392102\n",
      "Iteration 400: Weights = [-0.01485654 -0.12221287  0.33451711  0.18053012], Bias = -0.025194461827225952\n",
      "Iteration 401: Weights = [-0.01487942 -0.12222035  0.33454597  0.18056575], Bias = -0.025199346253874846\n",
      "Iteration 402: Weights = [-0.01490227 -0.12222778  0.33457476  0.18060134], Bias = -0.025204220125828836\n",
      "Iteration 403: Weights = [-0.01492509 -0.12223516  0.33460349  0.18063691], Bias = -0.025209083465002977\n",
      "Iteration 404: Weights = [-0.01494789 -0.1222425   0.33463215  0.18067244], Bias = -0.025213936293266327\n",
      "Iteration 405: Weights = [-0.01497066 -0.12224979  0.33466074  0.18070793], Bias = -0.025218778632442058\n",
      "Iteration 406: Weights = [-0.01499341 -0.12225703  0.33468927  0.1807434 ], Bias = -0.025223610504307548\n",
      "Iteration 407: Weights = [-0.01501613 -0.12226422  0.33471774  0.18077883], Bias = -0.025228431930594476\n",
      "Iteration 408: Weights = [-0.01503882 -0.12227137  0.33474614  0.18081423], Bias = -0.02523324293298892\n",
      "Iteration 409: Weights = [-0.01506149 -0.12227847  0.33477447  0.1808496 ], Bias = -0.025238043533131454\n",
      "Iteration 410: Weights = [-0.01508414 -0.12228553  0.33480274  0.18088494], Bias = -0.02524283375261723\n",
      "Iteration 411: Weights = [-0.01510676 -0.12229253  0.33483095  0.18092024], Bias = -0.025247613612996104\n",
      "Iteration 412: Weights = [-0.01512935 -0.1222995   0.33485909  0.18095552], Bias = -0.02525238313577269\n",
      "Iteration 413: Weights = [-0.01515191 -0.12230641  0.33488717  0.18099076], Bias = -0.025257142342406492\n",
      "Iteration 414: Weights = [-0.01517446 -0.12231328  0.33491518  0.18102597], Bias = -0.025261891254311972\n",
      "Iteration 415: Weights = [-0.01519697 -0.12232011  0.33494313  0.18106114], Bias = -0.025266629892858664\n",
      "Iteration 416: Weights = [-0.01521946 -0.12232689  0.33497101  0.18109629], Bias = -0.02527135827937126\n",
      "Iteration 417: Weights = [-0.01524193 -0.12233362  0.33499884  0.18113141], Bias = -0.025276076435129698\n",
      "Iteration 418: Weights = [-0.01526437 -0.12234031  0.33502659  0.18116649], Bias = -0.025280784381369267\n",
      "Iteration 419: Weights = [-0.01528678 -0.12234695  0.33505429  0.18120154], Bias = -0.025285482139280696\n",
      "Iteration 420: Weights = [-0.01530917 -0.12235355  0.33508192  0.18123656], Bias = -0.025290169730010244\n",
      "Iteration 421: Weights = [-0.01533154 -0.1223601   0.33510949  0.18127155], Bias = -0.0252948471746598\n",
      "Iteration 422: Weights = [-0.01535388 -0.1223666   0.335137    0.18130651], Bias = -0.02529951449428697\n",
      "Iteration 423: Weights = [-0.01537619 -0.12237306  0.33516444  0.18134143], Bias = -0.02530417170990518\n",
      "Iteration 424: Weights = [-0.01539848 -0.12237948  0.33519182  0.18137633], Bias = -0.025308818842483753\n",
      "Iteration 425: Weights = [-0.01542074 -0.12238585  0.33521914  0.18141119], Bias = -0.02531345591294801\n",
      "Iteration 426: Weights = [-0.01544298 -0.12239218  0.33524639  0.18144603], Bias = -0.02531808294217937\n",
      "Iteration 427: Weights = [-0.0154652  -0.12239846  0.33527359  0.18148083], Bias = -0.025322699951015434\n",
      "Iteration 428: Weights = [-0.01548739 -0.12240469  0.33530072  0.1815156 ], Bias = -0.02532730696025007\n",
      "Iteration 429: Weights = [-0.01550955 -0.12241088  0.33532779  0.18155034], Bias = -0.025331903990633522\n",
      "Iteration 430: Weights = [-0.0155317  -0.12241703  0.33535479  0.18158505], Bias = -0.025336491062872484\n",
      "Iteration 431: Weights = [-0.01555381 -0.12242314  0.33538174  0.18161973], Bias = -0.025341068197630205\n",
      "Iteration 432: Weights = [-0.0155759  -0.12242919  0.33540862  0.18165438], Bias = -0.02534563541552657\n",
      "Iteration 433: Weights = [-0.01559797 -0.12243521  0.33543544  0.181689  ], Bias = -0.0253501927371382\n",
      "Iteration 434: Weights = [-0.01562001 -0.12244118  0.3354622   0.18172359], Bias = -0.025354740182998544\n",
      "Iteration 435: Weights = [-0.01564203 -0.12244711  0.3354889   0.18175815], Bias = -0.02535927777359795\n",
      "Iteration 436: Weights = [-0.01566403 -0.12245299  0.33551554  0.18179268], Bias = -0.02536380552938378\n",
      "Iteration 437: Weights = [-0.015686   -0.12245883  0.33554212  0.18182717], Bias = -0.025368323470760488\n",
      "Iteration 438: Weights = [-0.01570794 -0.12246462  0.33556864  0.18186164], Bias = -0.025372831618089713\n",
      "Iteration 439: Weights = [-0.01572986 -0.12247038  0.33559509  0.18189608], Bias = -0.025377329991690366\n",
      "Iteration 440: Weights = [-0.01575176 -0.12247608  0.33562149  0.18193048], Bias = -0.025381818611838722\n",
      "Iteration 441: Weights = [-0.01577363 -0.12248175  0.33564782  0.18196486], Bias = -0.02538629749876851\n",
      "Iteration 442: Weights = [-0.01579548 -0.12248737  0.33567409  0.18199921], Bias = -0.025390766672671004\n",
      "Iteration 443: Weights = [-0.0158173  -0.12249295  0.33570031  0.18203352], Bias = -0.025395226153695105\n",
      "Iteration 444: Weights = [-0.01583911 -0.12249848  0.33572646  0.18206781], Bias = -0.025399675961947435\n",
      "Iteration 445: Weights = [-0.01586088 -0.12250398  0.33575255  0.18210207], Bias = -0.025404116117492426\n",
      "Iteration 446: Weights = [-0.01588264 -0.12250943  0.33577859  0.18213629], Bias = -0.025408546640352414\n",
      "Iteration 447: Weights = [-0.01590436 -0.12251483  0.33580456  0.18217049], Bias = -0.025412967550507714\n",
      "Iteration 448: Weights = [-0.01592607 -0.1225202   0.33583048  0.18220466], Bias = -0.025417378867896714\n",
      "Iteration 449: Weights = [-0.01594775 -0.12252552  0.33585633  0.1822388 ], Bias = -0.025421780612415974\n",
      "Iteration 450: Weights = [-0.01596941 -0.1225308   0.33588213  0.18227291], Bias = -0.025426172803920295\n",
      "Iteration 451: Weights = [-0.01599104 -0.12253603  0.33590786  0.18230699], Bias = -0.02543055546222282\n",
      "Iteration 452: Weights = [-0.01601265 -0.12254123  0.33593354  0.18234104], Bias = -0.025434928607095116\n",
      "Iteration 453: Weights = [-0.01603424 -0.12254638  0.33595916  0.18237506], Bias = -0.025439292258267267\n",
      "Iteration 454: Weights = [-0.01605581 -0.12255149  0.33598472  0.18240905], Bias = -0.02544364643542795\n",
      "Iteration 455: Weights = [-0.01607735 -0.12255655  0.33601022  0.18244301], Bias = -0.025447991158224537\n",
      "Iteration 456: Weights = [-0.01609886 -0.12256158  0.33603566  0.18247694], Bias = -0.025452326446263166\n",
      "Iteration 457: Weights = [-0.01612036 -0.12256656  0.33606104  0.18251085], Bias = -0.02545665231910884\n",
      "Iteration 458: Weights = [-0.01614183 -0.1225715   0.33608637  0.18254472], Bias = -0.025460968796285503\n",
      "Iteration 459: Weights = [-0.01616327 -0.1225764   0.33611163  0.18257857], Bias = -0.025465275897276138\n",
      "Iteration 460: Weights = [-0.0161847  -0.12258126  0.33613684  0.18261239], Bias = -0.025469573641522844\n",
      "Iteration 461: Weights = [-0.0162061  -0.12258608  0.33616199  0.18264617], Bias = -0.025473862048426922\n",
      "Iteration 462: Weights = [-0.01622748 -0.12259085  0.33618709  0.18267993], Bias = -0.02547814113734897\n",
      "Iteration 463: Weights = [-0.01624883 -0.12259558  0.33621212  0.18271366], Bias = -0.02548241092760895\n",
      "Iteration 464: Weights = [-0.01627016 -0.12260028  0.3362371   0.18274737], Bias = -0.025486671438486295\n",
      "Iteration 465: Weights = [-0.01629147 -0.12260493  0.33626202  0.18278104], Bias = -0.025490922689219982\n",
      "Iteration 466: Weights = [-0.01631276 -0.12260954  0.33628688  0.18281468], Bias = -0.025495164699008616\n",
      "Iteration 467: Weights = [-0.01633402 -0.12261411  0.33631168  0.1828483 ], Bias = -0.02549939748701052\n",
      "Iteration 468: Weights = [-0.01635526 -0.12261863  0.33633643  0.18288189], Bias = -0.025503621072343812\n",
      "Iteration 469: Weights = [-0.01637647 -0.12262312  0.33636112  0.18291545], Bias = -0.025507835474086506\n",
      "Iteration 470: Weights = [-0.01639767 -0.12262757  0.33638576  0.18294898], Bias = -0.025512040711276572\n",
      "Iteration 471: Weights = [-0.01641884 -0.12263197  0.33641033  0.18298248], Bias = -0.02551623680291204\n",
      "Iteration 472: Weights = [-0.01643999 -0.12263634  0.33643485  0.18301596], Bias = -0.025520423767951075\n",
      "Iteration 473: Weights = [-0.01646112 -0.12264066  0.33645932  0.1830494 ], Bias = -0.025524601625312063\n",
      "Iteration 474: Weights = [-0.01648222 -0.12264495  0.33648373  0.18308282], Bias = -0.025528770393873693\n",
      "Iteration 475: Weights = [-0.0165033  -0.12264919  0.33650808  0.18311621], Bias = -0.02553293009247504\n",
      "Iteration 476: Weights = [-0.01652436 -0.1226534   0.33653237  0.18314957], Bias = -0.025537080739915653\n",
      "Iteration 477: Weights = [-0.01654539 -0.12265756  0.33655661  0.18318291], Bias = -0.025541222354955633\n",
      "Iteration 478: Weights = [-0.01656641 -0.12266168  0.33658079  0.18321621], Bias = -0.025545354956315713\n",
      "Iteration 479: Weights = [-0.0165874  -0.12266577  0.33660492  0.18324949], Bias = -0.025549478562677353\n",
      "Iteration 480: Weights = [-0.01660837 -0.12266981  0.33662899  0.18328274], Bias = -0.025553593192682807\n",
      "Iteration 481: Weights = [-0.01662932 -0.12267381  0.33665301  0.18331597], Bias = -0.025557698864935214\n",
      "Iteration 482: Weights = [-0.01665024 -0.12267778  0.33667697  0.18334916], Bias = -0.025561795597998684\n",
      "Iteration 483: Weights = [-0.01667114 -0.1226817   0.33670087  0.18338233], Bias = -0.02556588341039837\n",
      "Iteration 484: Weights = [-0.01669202 -0.12268559  0.33672472  0.18341547], Bias = -0.02556996232062055\n",
      "Iteration 485: Weights = [-0.01671288 -0.12268943  0.33674851  0.18344858], Bias = -0.02557403234711272\n",
      "Iteration 486: Weights = [-0.01673372 -0.12269324  0.33677225  0.18348167], Bias = -0.025578093508283672\n",
      "Iteration 487: Weights = [-0.01675453 -0.12269701  0.33679594  0.18351473], Bias = -0.025582145822503562\n",
      "Iteration 488: Weights = [-0.01677533 -0.12270073  0.33681956  0.18354776], Bias = -0.025586189308104003\n",
      "Iteration 489: Weights = [-0.0167961  -0.12270442  0.33684314  0.18358076], Bias = -0.02559022398337815\n",
      "Iteration 490: Weights = [-0.01681684 -0.12270807  0.33686666  0.18361374], Bias = -0.025594249866580765\n",
      "Iteration 491: Weights = [-0.01683757 -0.12271168  0.33689012  0.18364669], Bias = -0.02559826697592832\n",
      "Iteration 492: Weights = [-0.01685828 -0.12271525  0.33691354  0.18367961], Bias = -0.02560227532959905\n",
      "Iteration 493: Weights = [-0.01687896 -0.12271879  0.33693689  0.1837125 ], Bias = -0.025606274945733056\n",
      "Iteration 494: Weights = [-0.01689962 -0.12272228  0.3369602   0.18374537], Bias = -0.025610265842432377\n",
      "Iteration 495: Weights = [-0.01692026 -0.12272574  0.33698344  0.18377821], Bias = -0.025614248037761068\n",
      "Iteration 496: Weights = [-0.01694088 -0.12272915  0.33700664  0.18381103], Bias = -0.02561822154974528\n",
      "Iteration 497: Weights = [-0.01696148 -0.12273253  0.33702978  0.18384381], Bias = -0.025622186396373342\n",
      "Iteration 498: Weights = [-0.01698205 -0.12273587  0.33705287  0.18387657], Bias = -0.02562614259559584\n",
      "Iteration 499: Weights = [-0.01700261 -0.12273918  0.3370759   0.18390931], Bias = -0.0256300901653257\n",
      "Iteration 500: Weights = [-0.01702314 -0.12274244  0.33709888  0.18394201], Bias = -0.025634029123438252\n",
      "Iteration 501: Weights = [-0.01704365 -0.12274567  0.33712181  0.18397469], Bias = -0.02563795948777133\n",
      "Iteration 502: Weights = [-0.01706414 -0.12274885  0.33714468  0.18400735], Bias = -0.025641881276125333\n",
      "Iteration 503: Weights = [-0.01708461 -0.122752    0.3371675   0.18403997], Bias = -0.025645794506263316\n",
      "Iteration 504: Weights = [-0.01710506 -0.12275512  0.33719027  0.18407258], Bias = -0.02564969919591106\n",
      "Iteration 505: Weights = [-0.01712548 -0.12275819  0.33721298  0.18410515], Bias = -0.025653595362757155\n",
      "Iteration 506: Weights = [-0.01714589 -0.12276123  0.33723565  0.1841377 ], Bias = -0.025657483024453077\n",
      "Iteration 507: Weights = [-0.01716627 -0.12276423  0.33725825  0.18417022], Bias = -0.025661362198613265\n",
      "Iteration 508: Weights = [-0.01718663 -0.12276719  0.33728081  0.18420271], Bias = -0.0256652329028152\n",
      "Iteration 509: Weights = [-0.01720698 -0.12277011  0.33730332  0.18423518], Bias = -0.025669095154599485\n",
      "Iteration 510: Weights = [-0.0172273  -0.122773    0.33732577  0.18426763], Bias = -0.025672948971469912\n",
      "Iteration 511: Weights = [-0.0172476  -0.12277585  0.33734817  0.18430004], Bias = -0.02567679437089355\n",
      "Iteration 512: Weights = [-0.01726788 -0.12277866  0.33737051  0.18433243], Bias = -0.02568063137030082\n",
      "Iteration 513: Weights = [-0.01728813 -0.12278144  0.33739281  0.1843648 ], Bias = -0.02568445998708557\n",
      "Iteration 514: Weights = [-0.01730837 -0.12278417  0.33741505  0.18439714], Bias = -0.02568828023860515\n",
      "Iteration 515: Weights = [-0.01732859 -0.12278688  0.33743724  0.18442945], Bias = -0.025692092142180496\n",
      "Iteration 516: Weights = [-0.01734878 -0.12278954  0.33745938  0.18446174], Bias = -0.025695895715096197\n",
      "Iteration 517: Weights = [-0.01736896 -0.12279217  0.33748147  0.184494  ], Bias = -0.02569969097460058\n",
      "Iteration 518: Weights = [-0.01738911 -0.12279476  0.33750351  0.18452624], Bias = -0.02570347793790578\n",
      "Iteration 519: Weights = [-0.01740925 -0.12279731  0.3375255   0.18455845], Bias = -0.025707256622187813\n",
      "Iteration 520: Weights = [-0.01742936 -0.12279983  0.33754743  0.18459063], Bias = -0.02571102704458666\n",
      "Iteration 521: Weights = [-0.01744945 -0.12280231  0.33756931  0.18462279], Bias = -0.02571478922220635\n",
      "Iteration 522: Weights = [-0.01746952 -0.12280476  0.33759115  0.18465492], Bias = -0.025718543172115006\n",
      "Iteration 523: Weights = [-0.01748957 -0.12280717  0.33761293  0.18468703], Bias = -0.025722288911344954\n",
      "Iteration 524: Weights = [-0.01750961 -0.12280954  0.33763466  0.18471911], Bias = -0.025726026456892773\n",
      "Iteration 525: Weights = [-0.01752962 -0.12281187  0.33765634  0.18475117], Bias = -0.02572975582571939\n",
      "Iteration 526: Weights = [-0.01754961 -0.12281417  0.33767797  0.1847832 ], Bias = -0.025733477034750138\n",
      "Iteration 527: Weights = [-0.01756958 -0.12281644  0.33769954  0.18481521], Bias = -0.025737190100874843\n",
      "Iteration 528: Weights = [-0.01758953 -0.12281867  0.33772107  0.18484719], Bias = -0.02574089504094789\n",
      "Iteration 529: Weights = [-0.01760946 -0.12282086  0.33774255  0.18487915], Bias = -0.025744591871788302\n",
      "Iteration 530: Weights = [-0.01762937 -0.12282302  0.33776398  0.18491108], Bias = -0.02574828061017981\n",
      "Iteration 531: Weights = [-0.01764926 -0.12282514  0.33778535  0.18494298], Bias = -0.02575196127287094\n",
      "Iteration 532: Weights = [-0.01766913 -0.12282722  0.33780668  0.18497486], Bias = -0.02575563387657507\n",
      "Iteration 533: Weights = [-0.01768897 -0.12282927  0.33782796  0.18500672], Bias = -0.025759298437970507\n",
      "Iteration 534: Weights = [-0.0177088  -0.12283129  0.33784919  0.18503855], Bias = -0.025762954973700573\n",
      "Iteration 535: Weights = [-0.01772861 -0.12283326  0.33787037  0.18507036], Bias = -0.02576660350037366\n",
      "Iteration 536: Weights = [-0.0177484  -0.12283521  0.33789149  0.18510214], Bias = -0.02577024403456333\n",
      "Iteration 537: Weights = [-0.01776817 -0.12283712  0.33791257  0.18513389], Bias = -0.025773876592808352\n",
      "Iteration 538: Weights = [-0.01778792 -0.12283899  0.3379336   0.18516563], Bias = -0.02577750119161281\n",
      "Iteration 539: Weights = [-0.01780765 -0.12284083  0.33795458  0.18519733], Bias = -0.025781117847446154\n",
      "Iteration 540: Weights = [-0.01782736 -0.12284263  0.33797552  0.18522902], Bias = -0.025784726576743276\n",
      "Iteration 541: Weights = [-0.01784705 -0.1228444   0.3379964   0.18526067], Bias = -0.02578832739590459\n",
      "Iteration 542: Weights = [-0.01786672 -0.12284613  0.33801723  0.18529231], Bias = -0.0257919203212961\n",
      "Iteration 543: Weights = [-0.01788637 -0.12284783  0.33803802  0.18532392], Bias = -0.02579550536924947\n",
      "Iteration 544: Weights = [-0.017906   -0.12284949  0.33805875  0.1853555 ], Bias = -0.0257990825560621\n",
      "Iteration 545: Weights = [-0.01792562 -0.12285112  0.33807944  0.18538706], Bias = -0.025802651897997193\n",
      "Iteration 546: Weights = [-0.01794521 -0.12285272  0.33810008  0.1854186 ], Bias = -0.025806213411283835\n",
      "Iteration 547: Weights = [-0.01796478 -0.12285428  0.33812067  0.18545011], Bias = -0.02580976711211706\n",
      "Iteration 548: Weights = [-0.01798433 -0.12285581  0.33814121  0.18548159], Bias = -0.02581331301665792\n",
      "Iteration 549: Weights = [-0.01800387 -0.1228573   0.3381617   0.18551306], Bias = -0.02581685114103356\n",
      "Iteration 550: Weights = [-0.01802338 -0.12285875  0.33818215  0.1855445 ], Bias = -0.025820381501337298\n",
      "Iteration 551: Weights = [-0.01804288 -0.12286018  0.33820255  0.18557591], Bias = -0.025823904113628674\n",
      "Iteration 552: Weights = [-0.01806235 -0.12286157  0.3382229   0.1856073 ], Bias = -0.02582741899393354\n",
      "Iteration 553: Weights = [-0.01808181 -0.12286292  0.3382432   0.18563867], Bias = -0.025830926158244123\n",
      "Iteration 554: Weights = [-0.01810125 -0.12286424  0.33826345  0.18567001], Bias = -0.025834425622519096\n",
      "Iteration 555: Weights = [-0.01812067 -0.12286553  0.33828366  0.18570133], Bias = -0.025837917402683652\n",
      "Iteration 556: Weights = [-0.01814007 -0.12286678  0.33830382  0.18573262], Bias = -0.02584140151462957\n",
      "Iteration 557: Weights = [-0.01815945 -0.122868    0.33832393  0.1857639 ], Bias = -0.02584487797421529\n",
      "Iteration 558: Weights = [-0.01817881 -0.12286919  0.33834399  0.18579514], Bias = -0.02584834679726597\n",
      "Iteration 559: Weights = [-0.01819815 -0.12287034  0.33836401  0.18582637], Bias = -0.025851807999573578\n",
      "Iteration 560: Weights = [-0.01821747 -0.12287146  0.33838398  0.18585757], Bias = -0.02585526159689694\n",
      "Iteration 561: Weights = [-0.01823677 -0.12287255  0.3384039   0.18588874], Bias = -0.025858707604961822\n",
      "Iteration 562: Weights = [-0.01825606 -0.1228736   0.33842378  0.1859199 ], Bias = -0.025862146039461\n",
      "Iteration 563: Weights = [-0.01827533 -0.12287462  0.33844361  0.18595103], Bias = -0.02586557691605432\n",
      "Iteration 564: Weights = [-0.01829457 -0.12287561  0.33846339  0.18598213], Bias = -0.025869000250368777\n",
      "Iteration 565: Weights = [-0.0183138  -0.12287656  0.33848312  0.18601322], Bias = -0.025872416057998577\n",
      "Iteration 566: Weights = [-0.01833301 -0.12287748  0.33850281  0.18604427], Bias = -0.02587582435450521\n",
      "Iteration 567: Weights = [-0.0183522  -0.12287837  0.33852246  0.18607531], Bias = -0.02587922515541751\n",
      "Iteration 568: Weights = [-0.01837137 -0.12287922  0.33854205  0.18610632], Bias = -0.025882618476231748\n",
      "Iteration 569: Weights = [-0.01839053 -0.12288004  0.3385616   0.18613731], Bias = -0.025886004332411665\n",
      "Iteration 570: Weights = [-0.01840966 -0.12288083  0.33858111  0.18616828], Bias = -0.025889382739388567\n",
      "Iteration 571: Weights = [-0.01842878 -0.12288158  0.33860056  0.18619922], Bias = -0.025892753712561382\n",
      "Iteration 572: Weights = [-0.01844788 -0.12288231  0.33861997  0.18623014], Bias = -0.025896117267296733\n",
      "Iteration 573: Weights = [-0.01846696 -0.122883    0.33863934  0.18626104], Bias = -0.025899473418929002\n",
      "Iteration 574: Weights = [-0.01848602 -0.12288366  0.33865866  0.18629191], Bias = -0.0259028221827604\n",
      "Iteration 575: Weights = [-0.01850506 -0.12288428  0.33867794  0.18632276], Bias = -0.02590616357406103\n",
      "Iteration 576: Weights = [-0.01852408 -0.12288487  0.33869716  0.18635359], Bias = -0.02590949760806896\n",
      "Iteration 577: Weights = [-0.01854309 -0.12288544  0.33871635  0.1863844 ], Bias = -0.02591282429999029\n",
      "Iteration 578: Weights = [-0.01856207 -0.12288596  0.33873549  0.18641518], Bias = -0.025916143664999215\n",
      "Iteration 579: Weights = [-0.01858104 -0.12288646  0.33875458  0.18644594], Bias = -0.025919455718238095\n",
      "Iteration 580: Weights = [-0.01859999 -0.12288693  0.33877363  0.18647667], Bias = -0.025922760474817518\n",
      "Iteration 581: Weights = [-0.01861893 -0.12288736  0.33879263  0.18650739], Bias = -0.025926057949816377\n",
      "Iteration 582: Weights = [-0.01863784 -0.12288776  0.33881159  0.18653808], Bias = -0.02592934815828192\n",
      "Iteration 583: Weights = [-0.01865674 -0.12288813  0.3388305   0.18656875], Bias = -0.025932631115229834\n",
      "Iteration 584: Weights = [-0.01867562 -0.12288846  0.33884937  0.18659939], Bias = -0.0259359068356443\n",
      "Iteration 585: Weights = [-0.01869448 -0.12288877  0.33886819  0.18663002], Bias = -0.025939175334478058\n",
      "Iteration 586: Weights = [-0.01871332 -0.12288904  0.33888697  0.18666062], Bias = -0.025942436626652486\n",
      "Iteration 587: Weights = [-0.01873214 -0.12288929  0.3389057   0.1866912 ], Bias = -0.02594569072705765\n",
      "Iteration 588: Weights = [-0.01875095 -0.1228895   0.33892439  0.18672175], Bias = -0.02594893765055238\n",
      "Iteration 589: Weights = [-0.01876974 -0.12288967  0.33894304  0.18675229], Bias = -0.02595217741196433\n",
      "Iteration 590: Weights = [-0.01878851 -0.12288982  0.33896164  0.1867828 ], Bias = -0.025955410026090045\n",
      "Iteration 591: Weights = [-0.01880726 -0.12288994  0.33898019  0.18681329], Bias = -0.02595863550769503\n",
      "Iteration 592: Weights = [-0.01882599 -0.12289002  0.33899871  0.18684376], Bias = -0.02596185387151381\n",
      "Iteration 593: Weights = [-0.01884471 -0.12289008  0.33901717  0.1868742 ], Bias = -0.025965065132249998\n",
      "Iteration 594: Weights = [-0.01886341 -0.1228901   0.3390356   0.18690463], Bias = -0.025968269304576363\n",
      "Iteration 595: Weights = [-0.01888209 -0.12289009  0.33905398  0.18693503], Bias = -0.025971466403134885\n",
      "Iteration 596: Weights = [-0.01890075 -0.12289005  0.33907232  0.18696541], Bias = -0.025974656442536825\n",
      "Iteration 597: Weights = [-0.0189194  -0.12288998  0.33909061  0.18699576], Bias = -0.025977839437362798\n",
      "Iteration 598: Weights = [-0.01893803 -0.12288988  0.33910886  0.1870261 ], Bias = -0.02598101540216282\n",
      "Iteration 599: Weights = [-0.01895664 -0.12288975  0.33912707  0.18705641], Bias = -0.02598418435145639\n",
      "Iteration 600: Weights = [-0.01897523 -0.12288959  0.33914523  0.1870867 ], Bias = -0.025987346299732535\n",
      "Iteration 601: Weights = [-0.01899381 -0.1228894   0.33916335  0.18711697], Bias = -0.025990501261449896\n",
      "Iteration 602: Weights = [-0.01901236 -0.12288917  0.33918143  0.18714722], Bias = -0.025993649251036775\n",
      "Iteration 603: Weights = [-0.0190309  -0.12288892  0.33919946  0.18717745], Bias = -0.025996790282891206\n",
      "Iteration 604: Weights = [-0.01904943 -0.12288864  0.33921745  0.18720765], Bias = -0.025999924371381013\n",
      "Iteration 605: Weights = [-0.01906793 -0.12288832  0.3392354   0.18723783], Bias = -0.02600305153084388\n",
      "Iteration 606: Weights = [-0.01908642 -0.12288798  0.33925331  0.187268  ], Bias = -0.02600617177558741\n",
      "Iteration 607: Weights = [-0.01910489 -0.1228876   0.33927117  0.18729814], Bias = -0.02600928511988919\n",
      "Iteration 608: Weights = [-0.01912335 -0.1228872   0.33928899  0.18732825], Bias = -0.026012391577996855\n",
      "Iteration 609: Weights = [-0.01914178 -0.12288676  0.33930677  0.18735835], Bias = -0.026015491164128147\n",
      "Iteration 610: Weights = [-0.0191602  -0.1228863   0.3393245   0.18738843], Bias = -0.026018583892470984\n",
      "Iteration 611: Weights = [-0.01917861 -0.1228858   0.33934219  0.18741848], Bias = -0.026021669777183513\n",
      "Iteration 612: Weights = [-0.01919699 -0.12288528  0.33935984  0.18744851], Bias = -0.02602474883239418\n",
      "Iteration 613: Weights = [-0.01921536 -0.12288472  0.33937745  0.18747852], Bias = -0.0260278210722018\n",
      "Iteration 614: Weights = [-0.01923371 -0.12288414  0.33939502  0.18750851], Bias = -0.026030886510675595\n",
      "Iteration 615: Weights = [-0.01925204 -0.12288352  0.33941254  0.18753848], Bias = -0.02603394516185528\n",
      "Iteration 616: Weights = [-0.01927036 -0.12288288  0.33943002  0.18756843], Bias = -0.02603699703975111\n",
      "Iteration 617: Weights = [-0.01928866 -0.12288221  0.33944746  0.18759836], Bias = -0.02604004215834396\n",
      "Iteration 618: Weights = [-0.01930694 -0.1228815   0.33946486  0.18762826], Bias = -0.026043080531585355\n",
      "Iteration 619: Weights = [-0.01932521 -0.12288077  0.33948222  0.18765815], Bias = -0.02604611217339757\n",
      "Iteration 620: Weights = [-0.01934346 -0.12288001  0.33949953  0.18768801], Bias = -0.02604913709767366\n",
      "Iteration 621: Weights = [-0.01936169 -0.12287922  0.33951681  0.18771785], Bias = -0.02605215531827754\n",
      "Iteration 622: Weights = [-0.01937991 -0.1228784   0.33953404  0.18774767], Bias = -0.026055166849044038\n",
      "Iteration 623: Weights = [-0.01939811 -0.12287755  0.33955123  0.18777747], Bias = -0.026058171703778957\n",
      "Iteration 624: Weights = [-0.01941629 -0.12287667  0.33956838  0.18780725], Bias = -0.02606116989625914\n",
      "Iteration 625: Weights = [-0.01943445 -0.12287576  0.33958549  0.18783701], Bias = -0.02606416144023252\n",
      "Iteration 626: Weights = [-0.0194526  -0.12287482  0.33960256  0.18786675], Bias = -0.026067146349418202\n",
      "Iteration 627: Weights = [-0.01947074 -0.12287386  0.33961959  0.18789647], Bias = -0.0260701246375065\n",
      "Iteration 628: Weights = [-0.01948885 -0.12287286  0.33963657  0.18792617], Bias = -0.026073096318159007\n",
      "Iteration 629: Weights = [-0.01950695 -0.12287184  0.33965352  0.18795584], Bias = -0.026076061405008656\n",
      "Iteration 630: Weights = [-0.01952503 -0.12287079  0.33967042  0.1879855 ], Bias = -0.026079019911659788\n",
      "Iteration 631: Weights = [-0.0195431  -0.12286971  0.33968729  0.18801513], Bias = -0.026081971851688195\n",
      "Iteration 632: Weights = [-0.01956115 -0.1228686   0.33970411  0.18804475], Bias = -0.026084917238641193\n",
      "Iteration 633: Weights = [-0.01957918 -0.12286746  0.33972089  0.18807434], Bias = -0.026087856086037677\n",
      "Iteration 634: Weights = [-0.0195972  -0.1228663   0.33973764  0.18810392], Bias = -0.026090788407368178\n",
      "Iteration 635: Weights = [-0.0196152  -0.1228651   0.33975434  0.18813347], Bias = -0.02609371421609493\n",
      "Iteration 636: Weights = [-0.01963318 -0.12286388  0.339771    0.188163  ], Bias = -0.026096633525651926\n",
      "Iteration 637: Weights = [-0.01965115 -0.12286263  0.33978762  0.18819252], Bias = -0.02609954634944497\n",
      "Iteration 638: Weights = [-0.0196691  -0.12286135  0.3398042   0.18822201], Bias = -0.02610245270085175\n",
      "Iteration 639: Weights = [-0.01968704 -0.12286004  0.33982075  0.18825148], Bias = -0.026105352593221887\n",
      "Iteration 640: Weights = [-0.01970496 -0.1228587   0.33983725  0.18828093], Bias = -0.026108246039876992\n",
      "Iteration 641: Weights = [-0.01972286 -0.12285734  0.33985371  0.18831036], Bias = -0.02611113305411074\n",
      "Iteration 642: Weights = [-0.01974075 -0.12285595  0.33987013  0.18833978], Bias = -0.026114013649188906\n",
      "Iteration 643: Weights = [-0.01975862 -0.12285453  0.33988652  0.18836917], Bias = -0.026116887838349444\n",
      "Iteration 644: Weights = [-0.01977647 -0.12285308  0.33990286  0.18839854], Bias = -0.026119755634802535\n",
      "Iteration 645: Weights = [-0.01979431 -0.12285161  0.33991917  0.18842789], Bias = -0.026122617051730645\n",
      "Iteration 646: Weights = [-0.01981213 -0.1228501   0.33993543  0.18845722], Bias = -0.02612547210228859\n",
      "Iteration 647: Weights = [-0.01982994 -0.12284857  0.33995166  0.18848654], Bias = -0.026128320799603585\n",
      "Iteration 648: Weights = [-0.01984773 -0.12284702  0.33996784  0.18851583], Bias = -0.02613116315677531\n",
      "Iteration 649: Weights = [-0.0198655  -0.12284543  0.33998399  0.1885451 ], Bias = -0.02613399918687596\n",
      "Iteration 650: Weights = [-0.01988326 -0.12284382  0.3400001   0.18857435], Bias = -0.026136828902950313\n",
      "Iteration 651: Weights = [-0.019901   -0.12284218  0.34001617  0.18860359], Bias = -0.026139652318015776\n",
      "Iteration 652: Weights = [-0.01991873 -0.12284051  0.3400322   0.1886328 ], Bias = -0.026142469445062454\n",
      "Iteration 653: Weights = [-0.01993644 -0.12283881  0.34004819  0.18866199], Bias = -0.026145280297053194\n",
      "Iteration 654: Weights = [-0.01995414 -0.12283709  0.34006414  0.18869117], Bias = -0.026148084886923658\n",
      "Iteration 655: Weights = [-0.01997182 -0.12283534  0.34008006  0.18872032], Bias = -0.026150883227582366\n",
      "Iteration 656: Weights = [-0.01998948 -0.12283356  0.34009594  0.18874945], Bias = -0.026153675331910757\n",
      "Iteration 657: Weights = [-0.02000713 -0.12283176  0.34011177  0.18877857], Bias = -0.02615646121276325\n",
      "Iteration 658: Weights = [-0.02002476 -0.12282993  0.34012757  0.18880767], Bias = -0.026159240882967304\n",
      "Iteration 659: Weights = [-0.02004238 -0.12282807  0.34014333  0.18883674], Bias = -0.02616201435532346\n",
      "Iteration 660: Weights = [-0.02005998 -0.12282619  0.34015906  0.1888658 ], Bias = -0.026164781642605408\n",
      "Iteration 661: Weights = [-0.02007757 -0.12282427  0.34017474  0.18889484], Bias = -0.026167542757560044\n",
      "Iteration 662: Weights = [-0.02009514 -0.12282234  0.34019039  0.18892385], Bias = -0.026170297712907527\n",
      "Iteration 663: Weights = [-0.02011269 -0.12282037  0.340206    0.18895285], Bias = -0.026173046521341326\n",
      "Iteration 664: Weights = [-0.02013023 -0.12281838  0.34022157  0.18898183], Bias = -0.026175789195528282\n",
      "Iteration 665: Weights = [-0.02014776 -0.12281636  0.3402371   0.18901079], Bias = -0.02617852574810867\n",
      "Iteration 666: Weights = [-0.02016526 -0.12281432  0.34025259  0.18903973], Bias = -0.026181256191696246\n",
      "Iteration 667: Weights = [-0.02018276 -0.12281224  0.34026805  0.18906866], Bias = -0.026183980538878302\n",
      "Iteration 668: Weights = [-0.02020024 -0.12281015  0.34028347  0.18909756], Bias = -0.02618669880221573\n",
      "Iteration 669: Weights = [-0.0202177  -0.12280802  0.34029885  0.18912644], Bias = -0.02618941099424307\n",
      "Iteration 670: Weights = [-0.02023515 -0.12280587  0.3403142   0.18915531], Bias = -0.026192117127468568\n",
      "Iteration 671: Weights = [-0.02025258 -0.1228037   0.34032951  0.18918415], Bias = -0.02619481721437423\n",
      "Iteration 672: Weights = [-0.02026999 -0.12280149  0.34034478  0.18921298], Bias = -0.026197511267415877\n",
      "Iteration 673: Weights = [-0.0202874  -0.12279926  0.34036001  0.18924179], Bias = -0.02620019929902321\n",
      "Iteration 674: Weights = [-0.02030478 -0.12279701  0.34037521  0.18927058], Bias = -0.02620288132159984\n",
      "Iteration 675: Weights = [-0.02032215 -0.12279473  0.34039037  0.18929935], Bias = -0.026205557347523376\n",
      "Iteration 676: Weights = [-0.02033951 -0.12279242  0.34040549  0.1893281 ], Bias = -0.02620822738914545\n",
      "Iteration 677: Weights = [-0.02035685 -0.12279009  0.34042057  0.18935683], Bias = -0.026210891458791786\n",
      "Iteration 678: Weights = [-0.02037418 -0.12278773  0.34043562  0.18938555], Bias = -0.026213549568762255\n",
      "Iteration 679: Weights = [-0.02039149 -0.12278534  0.34045063  0.18941424], Bias = -0.026216201731330924\n",
      "Iteration 680: Weights = [-0.02040879 -0.12278293  0.34046561  0.18944292], Bias = -0.026218847958746114\n",
      "Iteration 681: Weights = [-0.02042607 -0.1227805   0.34048055  0.18947158], Bias = -0.026221488263230452\n",
      "Iteration 682: Weights = [-0.02044333 -0.12277804  0.34049545  0.18950022], Bias = -0.026224122656980927\n",
      "Iteration 683: Weights = [-0.02046058 -0.12277555  0.34051031  0.18952884], Bias = -0.02622675115216894\n",
      "Iteration 684: Weights = [-0.02047782 -0.12277304  0.34052514  0.18955744], Bias = -0.026229373760940363\n",
      "Iteration 685: Weights = [-0.02049504 -0.1227705   0.34053994  0.18958602], Bias = -0.026231990495415587\n",
      "Iteration 686: Weights = [-0.02051225 -0.12276794  0.34055469  0.18961459], Bias = -0.026234601367689576\n",
      "Iteration 687: Weights = [-0.02052944 -0.12276535  0.34056942  0.18964314], Bias = -0.02623720638983193\n",
      "Iteration 688: Weights = [-0.02054662 -0.12276273  0.3405841   0.18967167], Bias = -0.026239805573886926\n",
      "Iteration 689: Weights = [-0.02056378 -0.12276009  0.34059875  0.18970018], Bias = -0.026242398931873575\n",
      "Iteration 690: Weights = [-0.02058093 -0.12275743  0.34061336  0.18972867], Bias = -0.026244986475785676\n",
      "Iteration 691: Weights = [-0.02059806 -0.12275474  0.34062794  0.18975714], Bias = -0.026247568217591874\n",
      "Iteration 692: Weights = [-0.02061518 -0.12275203  0.34064248  0.1897856 ], Bias = -0.0262501441692357\n",
      "Iteration 693: Weights = [-0.02063229 -0.12274929  0.34065699  0.18981404], Bias = -0.026252714342635642\n",
      "Iteration 694: Weights = [-0.02064937 -0.12274652  0.34067146  0.18984246], Bias = -0.026255278749685175\n",
      "Iteration 695: Weights = [-0.02066645 -0.12274373  0.34068589  0.18987086], Bias = -0.026257837402252834\n",
      "Iteration 696: Weights = [-0.02068351 -0.12274092  0.34070029  0.18989924], Bias = -0.026260390312182254\n",
      "Iteration 697: Weights = [-0.02070056 -0.12273808  0.34071465  0.18992761], Bias = -0.02626293749129223\n",
      "Iteration 698: Weights = [-0.02071759 -0.12273522  0.34072898  0.18995595], Bias = -0.026265478951376757\n",
      "Iteration 699: Weights = [-0.0207346  -0.12273233  0.34074328  0.18998428], Bias = -0.0262680147042051\n",
      "Iteration 700: Weights = [-0.02075161 -0.12272941  0.34075753  0.19001259], Bias = -0.02627054476152183\n",
      "Iteration 701: Weights = [-0.0207686  -0.12272648  0.34077176  0.19004089], Bias = -0.026273069135046893\n",
      "Iteration 702: Weights = [-0.02078557 -0.12272352  0.34078595  0.19006916], Bias = -0.026275587836475635\n",
      "Iteration 703: Weights = [-0.02080253 -0.12272053  0.3408001   0.19009742], Bias = -0.026278100877478876\n",
      "Iteration 704: Weights = [-0.02081947 -0.12271752  0.34081422  0.19012566], Bias = -0.02628060826970296\n",
      "Iteration 705: Weights = [-0.02083641 -0.12271448  0.3408283   0.19015388], Bias = -0.026283110024769792\n",
      "Iteration 706: Weights = [-0.02085332 -0.12271142  0.34084235  0.19018209], Bias = -0.02628560615427691\n",
      "Iteration 707: Weights = [-0.02087022 -0.12270834  0.34085636  0.19021027], Bias = -0.026288096669797516\n",
      "Iteration 708: Weights = [-0.02088711 -0.12270523  0.34087034  0.19023844], Bias = -0.02629058158288054\n",
      "Iteration 709: Weights = [-0.02090399 -0.1227021   0.34088429  0.19026659], Bias = -0.026293060905050684\n",
      "Iteration 710: Weights = [-0.02092085 -0.12269894  0.3408982   0.19029473], Bias = -0.02629553464780848\n",
      "Iteration 711: Weights = [-0.02093769 -0.12269576  0.34091208  0.19032285], Bias = -0.02629800282263033\n",
      "Iteration 712: Weights = [-0.02095453 -0.12269256  0.34092592  0.19035094], Bias = -0.02630046544096857\n",
      "Iteration 713: Weights = [-0.02097134 -0.12268933  0.34093973  0.19037903], Bias = -0.02630292251425151\n",
      "Iteration 714: Weights = [-0.02098815 -0.12268608  0.3409535   0.19040709], Bias = -0.026305374053883484\n",
      "Iteration 715: Weights = [-0.02100494 -0.12268281  0.34096724  0.19043514], Bias = -0.026307820071244915\n",
      "Iteration 716: Weights = [-0.02102171 -0.12267951  0.34098095  0.19046317], Bias = -0.026310260577692347\n",
      "Iteration 717: Weights = [-0.02103848 -0.12267618  0.34099462  0.19049118], Bias = -0.026312695584558506\n",
      "Iteration 718: Weights = [-0.02105522 -0.12267284  0.34100826  0.19051917], Bias = -0.026315125103152343\n",
      "Iteration 719: Weights = [-0.02107196 -0.12266947  0.34102186  0.19054715], Bias = -0.02631754914475909\n",
      "Iteration 720: Weights = [-0.02108868 -0.12266607  0.34103543  0.19057511], Bias = -0.026319967720640308\n",
      "Iteration 721: Weights = [-0.02110538 -0.12266266  0.34104897  0.19060305], Bias = -0.026322380842033935\n",
      "Iteration 722: Weights = [-0.02112208 -0.12265921  0.34106247  0.19063098], Bias = -0.026324788520154338\n",
      "Iteration 723: Weights = [-0.02113876 -0.12265575  0.34107594  0.19065889], Bias = -0.02632719076619236\n",
      "Iteration 724: Weights = [-0.02115542 -0.12265226  0.34108938  0.19068678], Bias = -0.026329587591315373\n",
      "Iteration 725: Weights = [-0.02117207 -0.12264875  0.34110278  0.19071465], Bias = -0.02633197900666732\n",
      "Iteration 726: Weights = [-0.02118871 -0.12264522  0.34111615  0.19074251], Bias = -0.026334365023368774\n",
      "Iteration 727: Weights = [-0.02120534 -0.12264166  0.34112949  0.19077035], Bias = -0.02633674565251698\n",
      "Iteration 728: Weights = [-0.02122195 -0.12263808  0.3411428   0.19079817], Bias = -0.026339120905185906\n",
      "Iteration 729: Weights = [-0.02123854 -0.12263448  0.34115607  0.19082598], Bias = -0.026341490792426293\n",
      "Iteration 730: Weights = [-0.02125513 -0.12263085  0.3411693   0.19085377], Bias = -0.0263438553252657\n",
      "Iteration 731: Weights = [-0.0212717  -0.1226272   0.34118251  0.19088154], Bias = -0.026346214514708557\n",
      "Iteration 732: Weights = [-0.02128825 -0.12262353  0.34119568  0.1909093 ], Bias = -0.026348568371736217\n",
      "Iteration 733: Weights = [-0.0213048  -0.12261984  0.34120882  0.19093704], Bias = -0.026350916907306992\n",
      "Iteration 734: Weights = [-0.02132132 -0.12261612  0.34122193  0.19096476], Bias = -0.02635326013235621\n",
      "Iteration 735: Weights = [-0.02133784 -0.12261238  0.341235    0.19099246], Bias = -0.026355598057796265\n",
      "Iteration 736: Weights = [-0.02135434 -0.12260861  0.34124804  0.19102015], Bias = -0.02635793069451666\n",
      "Iteration 737: Weights = [-0.02137083 -0.12260483  0.34126105  0.19104783], Bias = -0.02636025805338406\n",
      "Iteration 738: Weights = [-0.02138731 -0.12260102  0.34127403  0.19107548], Bias = -0.026362580145242332\n",
      "Iteration 739: Weights = [-0.02140377 -0.12259719  0.34128697  0.19110312], Bias = -0.026364896980912603\n",
      "Iteration 740: Weights = [-0.02142022 -0.12259333  0.34129988  0.19113074], Bias = -0.0263672085711933\n",
      "Iteration 741: Weights = [-0.02143665 -0.12258946  0.34131276  0.19115835], Bias = -0.026369514926860203\n",
      "Iteration 742: Weights = [-0.02145308 -0.12258556  0.34132561  0.19118594], Bias = -0.026371816058666488\n",
      "Iteration 743: Weights = [-0.02146949 -0.12258164  0.34133842  0.19121351], Bias = -0.026374111977342775\n",
      "Iteration 744: Weights = [-0.02148588 -0.1225777   0.34135121  0.19124107], Bias = -0.026376402693597176\n",
      "Iteration 745: Weights = [-0.02150226 -0.12257373  0.34136396  0.19126861], Bias = -0.026378688218115353\n",
      "Iteration 746: Weights = [-0.02151863 -0.12256974  0.34137668  0.19129613], Bias = -0.026380968561560542\n",
      "Iteration 747: Weights = [-0.02153499 -0.12256573  0.34138937  0.19132364], Bias = -0.026383243734573618\n",
      "Iteration 748: Weights = [-0.02155133 -0.1225617   0.34140202  0.19135113], Bias = -0.02638551374777314\n",
      "Iteration 749: Weights = [-0.02156766 -0.12255765  0.34141465  0.1913786 ], Bias = -0.026387778611755397\n",
      "Iteration 750: Weights = [-0.02158398 -0.12255357  0.34142724  0.19140606], Bias = -0.026390038337094444\n",
      "Iteration 751: Weights = [-0.02160029 -0.12254947  0.3414398   0.1914335 ], Bias = -0.02639229293434216\n",
      "Iteration 752: Weights = [-0.02161658 -0.12254535  0.34145233  0.19146093], Bias = -0.026394542414028298\n",
      "Iteration 753: Weights = [-0.02163285 -0.12254121  0.34146483  0.19148834], Bias = -0.02639678678666052\n",
      "Iteration 754: Weights = [-0.02164912 -0.12253705  0.34147729  0.19151573], Bias = -0.026399026062724453\n",
      "Iteration 755: Weights = [-0.02166537 -0.12253286  0.34148973  0.19154311], Bias = -0.026401260252683727\n",
      "Iteration 756: Weights = [-0.02168161 -0.12252865  0.34150213  0.19157047], Bias = -0.02640348936698003\n",
      "Iteration 757: Weights = [-0.02169784 -0.12252442  0.3415145   0.19159782], Bias = -0.02640571341603314\n",
      "Iteration 758: Weights = [-0.02171405 -0.12252017  0.34152685  0.19162515], Bias = -0.02640793241024099\n",
      "Iteration 759: Weights = [-0.02173025 -0.1225159   0.34153916  0.19165246], Bias = -0.0264101463599797\n",
      "Iteration 760: Weights = [-0.02174644 -0.12251161  0.34155144  0.19167976], Bias = -0.026412355275603632\n",
      "Iteration 761: Weights = [-0.02176262 -0.12250729  0.34156368  0.19170704], Bias = -0.02641455916744542\n",
      "Iteration 762: Weights = [-0.02177878 -0.12250296  0.3415759   0.1917343 ], Bias = -0.026416758045816034\n",
      "Iteration 763: Weights = [-0.02179493 -0.1224986   0.34158809  0.19176155], Bias = -0.026418951921004817\n",
      "Iteration 764: Weights = [-0.02181106 -0.12249422  0.34160025  0.19178879], Bias = -0.026421140803279532\n",
      "Iteration 765: Weights = [-0.02182719 -0.12248982  0.34161237  0.191816  ], Bias = -0.026423324702886403\n",
      "Iteration 766: Weights = [-0.0218433  -0.1224854   0.34162447  0.19184321], Bias = -0.026425503630050168\n",
      "Iteration 767: Weights = [-0.0218594  -0.12248095  0.34163653  0.19187039], Bias = -0.026427677594974115\n",
      "Iteration 768: Weights = [-0.02187549 -0.12247649  0.34164856  0.19189756], Bias = -0.026429846607840136\n",
      "Iteration 769: Weights = [-0.02189156 -0.122472    0.34166057  0.19192472], Bias = -0.026432010678808765\n",
      "Iteration 770: Weights = [-0.02190762 -0.1224675   0.34167254  0.19195186], Bias = -0.026434169818019226\n",
      "Iteration 771: Weights = [-0.02192367 -0.12246297  0.34168448  0.19197898], Bias = -0.026436324035589476\n",
      "Iteration 772: Weights = [-0.02193971 -0.12245842  0.3416964   0.19200609], Bias = -0.026438473341616257\n",
      "Iteration 773: Weights = [-0.02195573 -0.12245385  0.34170828  0.19203319], Bias = -0.026440617746175125\n",
      "Iteration 774: Weights = [-0.02197174 -0.12244926  0.34172013  0.19206026], Bias = -0.026442757259320514\n",
      "Iteration 775: Weights = [-0.02198774 -0.12244465  0.34173196  0.19208732], Bias = -0.026444891891085762\n",
      "Iteration 776: Weights = [-0.02200372 -0.12244002  0.34174375  0.19211437], Bias = -0.02644702165148317\n",
      "Iteration 777: Weights = [-0.0220197  -0.12243537  0.34175551  0.1921414 ], Bias = -0.026449146550504034\n",
      "Iteration 778: Weights = [-0.02203566 -0.1224307   0.34176724  0.19216842], Bias = -0.0264512665981187\n",
      "Iteration 779: Weights = [-0.02205161 -0.122426    0.34177895  0.19219542], Bias = -0.0264533818042766\n",
      "Iteration 780: Weights = [-0.02206755 -0.12242129  0.34179062  0.1922224 ], Bias = -0.0264554921789063\n",
      "Iteration 781: Weights = [-0.02208347 -0.12241655  0.34180226  0.19224937], Bias = -0.026457597731915538\n",
      "Iteration 782: Weights = [-0.02209938 -0.1224118   0.34181388  0.19227633], Bias = -0.026459698473191278\n",
      "Iteration 783: Weights = [-0.02211528 -0.12240702  0.34182546  0.19230327], Bias = -0.026461794412599743\n",
      "Iteration 784: Weights = [-0.02213117 -0.12240223  0.34183702  0.19233019], Bias = -0.02646388555998647\n",
      "Iteration 785: Weights = [-0.02214705 -0.12239741  0.34184854  0.1923571 ], Bias = -0.026465971925176343\n",
      "Iteration 786: Weights = [-0.02216291 -0.12239257  0.34186004  0.19238399], Bias = -0.026468053517973638\n",
      "Iteration 787: Weights = [-0.02217876 -0.12238772  0.34187151  0.19241087], Bias = -0.026470130348162074\n",
      "Iteration 788: Weights = [-0.0221946  -0.12238284  0.34188295  0.19243773], Bias = -0.026472202425504843\n",
      "Iteration 789: Weights = [-0.02221043 -0.12237794  0.34189436  0.19246458], Bias = -0.026474269759744668\n",
      "Iteration 790: Weights = [-0.02222624 -0.12237302  0.34190574  0.19249142], Bias = -0.026476332360603833\n",
      "Iteration 791: Weights = [-0.02224204 -0.12236808  0.34191709  0.19251823], Bias = -0.026478390237784238\n",
      "Iteration 792: Weights = [-0.02225784 -0.12236313  0.34192841  0.19254504], Bias = -0.02648044340096743\n",
      "Iteration 793: Weights = [-0.02227361 -0.12235815  0.3419397   0.19257183], Bias = -0.02648249185981465\n",
      "Iteration 794: Weights = [-0.02228938 -0.12235315  0.34195096  0.1925986 ], Bias = -0.02648453562396688\n",
      "Iteration 795: Weights = [-0.02230514 -0.12234813  0.3419622   0.19262536], Bias = -0.026486574703044885\n",
      "Iteration 796: Weights = [-0.02232088 -0.1223431   0.34197341  0.1926521 ], Bias = -0.026488609106649248\n",
      "Iteration 797: Weights = [-0.02233661 -0.12233804  0.34198458  0.19267883], Bias = -0.02649063884436042\n",
      "Iteration 798: Weights = [-0.02235233 -0.12233296  0.34199573  0.19270554], Bias = -0.026492663925738753\n",
      "Iteration 799: Weights = [-0.02236804 -0.12232786  0.34200685  0.19273224], Bias = -0.026494684360324556\n",
      "Iteration 800: Weights = [-0.02238373 -0.12232275  0.34201795  0.19275893], Bias = -0.02649670015763813\n",
      "Iteration 801: Weights = [-0.02239941 -0.12231761  0.34202901  0.1927856 ], Bias = -0.026498711327179802\n",
      "Iteration 802: Weights = [-0.02241509 -0.12231246  0.34204005  0.19281225], Bias = -0.02650071787842998\n",
      "Iteration 803: Weights = [-0.02243075 -0.12230728  0.34205105  0.19283889], Bias = -0.02650271982084919\n",
      "Iteration 804: Weights = [-0.02244639 -0.12230209  0.34206203  0.19286552], Bias = -0.026504717163878116\n",
      "Iteration 805: Weights = [-0.02246203 -0.12229687  0.34207298  0.19289213], Bias = -0.02650670991693764\n",
      "Iteration 806: Weights = [-0.02247766 -0.12229164  0.34208391  0.19291873], Bias = -0.026508698089428892\n",
      "Iteration 807: Weights = [-0.02249327 -0.12228638  0.3420948   0.19294531], Bias = -0.02651068169073328\n",
      "Iteration 808: Weights = [-0.02250887 -0.12228111  0.34210567  0.19297188], Bias = -0.02651266073021254\n",
      "Iteration 809: Weights = [-0.02252446 -0.12227582  0.3421165   0.19299843], Bias = -0.026514635217208773\n",
      "Iteration 810: Weights = [-0.02254004 -0.12227051  0.34212732  0.19302497], Bias = -0.02651660516104449\n",
      "Iteration 811: Weights = [-0.0225556  -0.12226518  0.3421381   0.19305149], Bias = -0.026518570571022648\n",
      "Iteration 812: Weights = [-0.02257116 -0.12225983  0.34214885  0.193078  ], Bias = -0.026520531456426695\n",
      "Iteration 813: Weights = [-0.0225867  -0.12225446  0.34215958  0.1931045 ], Bias = -0.026522487826520613\n",
      "Iteration 814: Weights = [-0.02260223 -0.12224907  0.34217028  0.19313098], Bias = -0.02652443969054895\n",
      "Iteration 815: Weights = [-0.02261775 -0.12224367  0.34218095  0.19315744], Bias = -0.026526387057736876\n",
      "Iteration 816: Weights = [-0.02263326 -0.12223824  0.3421916   0.1931839 ], Bias = -0.0265283299372902\n",
      "Iteration 817: Weights = [-0.02264876 -0.1222328   0.34220221  0.19321033], Bias = -0.026530268338395436\n",
      "Iteration 818: Weights = [-0.02266424 -0.12222733  0.3422128   0.19323676], Bias = -0.026532202270219827\n",
      "Iteration 819: Weights = [-0.02267972 -0.12222185  0.34222337  0.19326317], Bias = -0.026534131741911396\n",
      "Iteration 820: Weights = [-0.02269518 -0.12221635  0.3422339   0.19328956], Bias = -0.026536056762598972\n",
      "Iteration 821: Weights = [-0.02271063 -0.12221083  0.34224441  0.19331594], Bias = -0.026537977341392252\n",
      "Iteration 822: Weights = [-0.02272607 -0.12220529  0.34225489  0.19334231], Bias = -0.026539893487381817\n",
      "Iteration 823: Weights = [-0.0227415  -0.12219973  0.34226534  0.19336866], Bias = -0.02654180520963919\n",
      "Iteration 824: Weights = [-0.02275692 -0.12219416  0.34227577  0.193395  ], Bias = -0.026543712517216867\n",
      "Iteration 825: Weights = [-0.02277233 -0.12218856  0.34228617  0.19342133], Bias = -0.026545615419148363\n",
      "Iteration 826: Weights = [-0.02278772 -0.12218295  0.34229654  0.19344764], Bias = -0.026547513924448245\n",
      "Iteration 827: Weights = [-0.0228031  -0.12217732  0.34230688  0.19347393], Bias = -0.02654940804211218\n",
      "Iteration 828: Weights = [-0.02281848 -0.12217167  0.3423172   0.19350022], Bias = -0.026551297781116957\n",
      "Iteration 829: Weights = [-0.02283384 -0.122166    0.34232749  0.19352649], Bias = -0.02655318315042056\n",
      "Iteration 830: Weights = [-0.02284919 -0.12216031  0.34233776  0.19355274], Bias = -0.02655506415896217\n",
      "Iteration 831: Weights = [-0.02286453 -0.12215461  0.342348    0.19357898], Bias = -0.02655694081566223\n",
      "Iteration 832: Weights = [-0.02287985 -0.12214888  0.34235821  0.19360521], Bias = -0.026558813129422473\n",
      "Iteration 833: Weights = [-0.02289517 -0.12214314  0.34236839  0.19363142], Bias = -0.026560681109125968\n",
      "Iteration 834: Weights = [-0.02291048 -0.12213738  0.34237855  0.19365762], Bias = -0.02656254476363715\n",
      "Iteration 835: Weights = [-0.02292577 -0.1221316   0.34238868  0.19368381], Bias = -0.026564404101801865\n",
      "Iteration 836: Weights = [-0.02294105 -0.12212581  0.34239879  0.19370998], Bias = -0.026566259132447412\n",
      "Iteration 837: Weights = [-0.02295633 -0.12211999  0.34240887  0.19373614], Bias = -0.02656810986438258\n",
      "Iteration 838: Weights = [-0.02297159 -0.12211416  0.34241892  0.19376228], Bias = -0.026569956306397677\n",
      "Iteration 839: Weights = [-0.02298684 -0.12210831  0.34242895  0.19378841], Bias = -0.026571798467264582\n",
      "Iteration 840: Weights = [-0.02300208 -0.12210244  0.34243895  0.19381453], Bias = -0.02657363635573678\n",
      "Iteration 841: Weights = [-0.02301731 -0.12209655  0.34244892  0.19384063], Bias = -0.026575469980549403\n",
      "Iteration 842: Weights = [-0.02303252 -0.12209065  0.34245887  0.19386672], Bias = -0.026577299350419255\n",
      "Iteration 843: Weights = [-0.02304773 -0.12208473  0.34246879  0.1938928 ], Bias = -0.026579124474044865\n",
      "Iteration 844: Weights = [-0.02306292 -0.12207878  0.34247869  0.19391886], Bias = -0.026580945360106523\n",
      "Iteration 845: Weights = [-0.02307811 -0.12207283  0.34248856  0.19394491], Bias = -0.026582762017266313\n",
      "Iteration 846: Weights = [-0.02309328 -0.12206685  0.34249841  0.19397095], Bias = -0.026584574454168158\n",
      "Iteration 847: Weights = [-0.02310845 -0.12206086  0.34250822  0.19399697], Bias = -0.026586382679437852\n",
      "Iteration 848: Weights = [-0.0231236  -0.12205485  0.34251802  0.19402298], Bias = -0.026588186701683097\n",
      "Iteration 849: Weights = [-0.02313874 -0.12204882  0.34252778  0.19404897], Bias = -0.02658998652949355\n",
      "Iteration 850: Weights = [-0.02315387 -0.12204277  0.34253753  0.19407495], Bias = -0.026591782171440852\n",
      "Iteration 851: Weights = [-0.02316899 -0.12203671  0.34254724  0.19410092], Bias = -0.026593573636078675\n",
      "Iteration 852: Weights = [-0.0231841  -0.12203062  0.34255693  0.19412688], Bias = -0.026595360931942744\n",
      "Iteration 853: Weights = [-0.0231992  -0.12202453  0.3425666   0.19415282], Bias = -0.02659714406755089\n",
      "Iteration 854: Weights = [-0.02321429 -0.12201841  0.34257624  0.19417875], Bias = -0.026598923051403087\n",
      "Iteration 855: Weights = [-0.02322936 -0.12201228  0.34258585  0.19420466], Bias = -0.026600697891981474\n",
      "Iteration 856: Weights = [-0.02324443 -0.12200612  0.34259544  0.19423057], Bias = -0.02660246859775041\n",
      "Iteration 857: Weights = [-0.02325948 -0.12199996  0.342605    0.19425646], Bias = -0.0266042351771565\n",
      "Iteration 858: Weights = [-0.02327453 -0.12199377  0.34261454  0.19428233], Bias = -0.026605997638628646\n",
      "Iteration 859: Weights = [-0.02328956 -0.12198757  0.34262405  0.19430819], Bias = -0.02660775599057806\n",
      "Iteration 860: Weights = [-0.02330459 -0.12198135  0.34263354  0.19433404], Bias = -0.02660951024139833\n",
      "Iteration 861: Weights = [-0.0233196  -0.12197511  0.342643    0.19435988], Bias = -0.026611260399465438\n",
      "Iteration 862: Weights = [-0.02333461 -0.12196885  0.34265244  0.1943857 ], Bias = -0.026613006473137794\n",
      "Iteration 863: Weights = [-0.0233496  -0.12196258  0.34266186  0.19441151], Bias = -0.026614748470756292\n",
      "Iteration 864: Weights = [-0.02336458 -0.12195629  0.34267124  0.19443731], Bias = -0.026616486400644332\n",
      "Iteration 865: Weights = [-0.02337955 -0.12194999  0.34268061  0.19446309], Bias = -0.02661822027110786\n",
      "Iteration 866: Weights = [-0.02339451 -0.12194367  0.34268994  0.19448887], Bias = -0.026619950090435402\n",
      "Iteration 867: Weights = [-0.02340946 -0.12193733  0.34269926  0.19451462], Bias = -0.026621675866898106\n",
      "Iteration 868: Weights = [-0.0234244  -0.12193097  0.34270855  0.19454037], Bias = -0.026623397608749776\n",
      "Iteration 869: Weights = [-0.02343933 -0.1219246   0.34271781  0.1945661 ], Bias = -0.02662511532422691\n",
      "Iteration 870: Weights = [-0.02345425 -0.12191821  0.34272705  0.19459182], Bias = -0.02662682902154873\n",
      "Iteration 871: Weights = [-0.02346916 -0.1219118   0.34273627  0.19461753], Bias = -0.026628538708917227\n",
      "Iteration 872: Weights = [-0.02348406 -0.12190538  0.34274546  0.19464322], Bias = -0.026630244394517194\n",
      "Iteration 873: Weights = [-0.02349895 -0.12189894  0.34275462  0.1946689 ], Bias = -0.026631946086516256\n",
      "Iteration 874: Weights = [-0.02351383 -0.12189248  0.34276377  0.19469457], Bias = -0.026633643793064914\n",
      "Iteration 875: Weights = [-0.0235287  -0.12188601  0.34277288  0.19472022], Bias = -0.026635337522296583\n",
      "Iteration 876: Weights = [-0.02354355 -0.12187952  0.34278198  0.19474587], Bias = -0.026637027282327617\n",
      "Iteration 877: Weights = [-0.0235584  -0.12187301  0.34279104  0.1947715 ], Bias = -0.02663871308125735\n",
      "Iteration 878: Weights = [-0.02357324 -0.12186649  0.34280009  0.19479711], Bias = -0.02664039492716814\n",
      "Iteration 879: Weights = [-0.02358806 -0.12185995  0.34280911  0.19482272], Bias = -0.026642072828125387\n",
      "Iteration 880: Weights = [-0.02360288 -0.12185339  0.34281811  0.19484831], Bias = -0.026643746792177587\n",
      "Iteration 881: Weights = [-0.02361769 -0.12184682  0.34282708  0.19487389], Bias = -0.02664541682735636\n",
      "Iteration 882: Weights = [-0.02363248 -0.12184023  0.34283603  0.19489946], Bias = -0.026647082941676475\n",
      "Iteration 883: Weights = [-0.02364727 -0.12183362  0.34284495  0.19492501], Bias = -0.02664874514313591\n",
      "Iteration 884: Weights = [-0.02366205 -0.121827    0.34285385  0.19495055], Bias = -0.02665040343971586\n",
      "Iteration 885: Weights = [-0.02367681 -0.12182036  0.34286273  0.19497608], Bias = -0.02665205783938079\n",
      "Iteration 886: Weights = [-0.02369157 -0.12181371  0.34287158  0.1950016 ], Bias = -0.02665370835007846\n",
      "Iteration 887: Weights = [-0.02370632 -0.12180704  0.34288041  0.1950271 ], Bias = -0.026655354979739972\n",
      "Iteration 888: Weights = [-0.02372105 -0.12180035  0.34288922  0.19505259], Bias = -0.026656997736279796\n",
      "Iteration 889: Weights = [-0.02373578 -0.12179365  0.342898    0.19507807], Bias = -0.0266586366275958\n",
      "Iteration 890: Weights = [-0.0237505  -0.12178693  0.34290676  0.19510354], Bias = -0.026660271661569302\n",
      "Iteration 891: Weights = [-0.0237652  -0.1217802   0.34291549  0.19512899], Bias = -0.026661902846065087\n",
      "Iteration 892: Weights = [-0.0237799  -0.12177345  0.3429242   0.19515443], Bias = -0.02666353018893145\n",
      "Iteration 893: Weights = [-0.02379458 -0.12176668  0.34293289  0.19517986], Bias = -0.026665153698000234\n",
      "Iteration 894: Weights = [-0.02380926 -0.1217599   0.34294156  0.19520528], Bias = -0.02666677338108685\n",
      "Iteration 895: Weights = [-0.02382393 -0.1217531   0.3429502   0.19523069], Bias = -0.026668389245990336\n",
      "Iteration 896: Weights = [-0.02383858 -0.12174629  0.34295882  0.19525608], Bias = -0.026670001300493365\n",
      "Iteration 897: Weights = [-0.02385323 -0.12173946  0.34296741  0.19528146], Bias = -0.026671609552362297\n",
      "Iteration 898: Weights = [-0.02386787 -0.12173261  0.34297598  0.19530683], Bias = -0.026673214009347208\n",
      "Iteration 899: Weights = [-0.0238825  -0.12172575  0.34298453  0.19533218], Bias = -0.02667481467918192\n",
      "Iteration 900: Weights = [-0.02389711 -0.12171887  0.34299306  0.19535753], Bias = -0.026676411569584044\n",
      "Iteration 901: Weights = [-0.02391172 -0.12171198  0.34300156  0.19538286], Bias = -0.026678004688255007\n",
      "Iteration 902: Weights = [-0.02392632 -0.12170507  0.34301004  0.19540818], Bias = -0.026679594042880086\n",
      "Iteration 903: Weights = [-0.02394091 -0.12169815  0.34301849  0.19543349], Bias = -0.026681179641128445\n",
      "Iteration 904: Weights = [-0.02395549 -0.12169121  0.34302693  0.19545878], Bias = -0.026682761490653167\n",
      "Iteration 905: Weights = [-0.02397005 -0.12168426  0.34303534  0.19548406], Bias = -0.026684339599091292\n",
      "Iteration 906: Weights = [-0.02398461 -0.12167728  0.34304372  0.19550934], Bias = -0.026685913974063842\n",
      "Iteration 907: Weights = [-0.02399916 -0.1216703   0.34305209  0.19553459], Bias = -0.026687484623175866\n",
      "Iteration 908: Weights = [-0.0240137  -0.1216633   0.34306043  0.19555984], Bias = -0.02668905155401646\n",
      "Iteration 909: Weights = [-0.02402823 -0.12165628  0.34306875  0.19558508], Bias = -0.026690614774158815\n",
      "Iteration 910: Weights = [-0.02404275 -0.12164925  0.34307705  0.1956103 ], Bias = -0.026692174291160237\n",
      "Iteration 911: Weights = [-0.02405726 -0.1216422   0.34308532  0.19563551], Bias = -0.02669373011256219\n",
      "Iteration 912: Weights = [-0.02407177 -0.12163514  0.34309357  0.19566071], Bias = -0.026695282245890326\n",
      "Iteration 913: Weights = [-0.02408626 -0.12162806  0.3431018   0.1956859 ], Bias = -0.026696830698654514\n",
      "Iteration 914: Weights = [-0.02410074 -0.12162097  0.34311001  0.19571107], Bias = -0.02669837547834888\n",
      "Iteration 915: Weights = [-0.02411521 -0.12161386  0.34311819  0.19573624], Bias = -0.02669991659245184\n",
      "Iteration 916: Weights = [-0.02412968 -0.12160674  0.34312636  0.19576139], Bias = -0.026701454048426127\n",
      "Iteration 917: Weights = [-0.02414413 -0.1215996   0.3431345   0.19578653], Bias = -0.026702987853718826\n",
      "Iteration 918: Weights = [-0.02415857 -0.12159244  0.34314261  0.19581166], Bias = -0.02670451801576141\n",
      "Iteration 919: Weights = [-0.02417301 -0.12158528  0.34315071  0.19583678], Bias = -0.02670604454196977\n",
      "Iteration 920: Weights = [-0.02418744 -0.12157809  0.34315878  0.19586188], Bias = -0.026707567439744246\n",
      "Iteration 921: Weights = [-0.02420185 -0.12157089  0.34316683  0.19588697], Bias = -0.026709086716469668\n",
      "Iteration 922: Weights = [-0.02421626 -0.12156368  0.34317486  0.19591206], Bias = -0.026710602379515377\n",
      "Iteration 923: Weights = [-0.02423066 -0.12155645  0.34318287  0.19593713], Bias = -0.026712114436235265\n",
      "Iteration 924: Weights = [-0.02424504 -0.12154921  0.34319086  0.19596218], Bias = -0.026713622893967805\n",
      "Iteration 925: Weights = [-0.02425942 -0.12154195  0.34319882  0.19598723], Bias = -0.026715127760036088\n",
      "Iteration 926: Weights = [-0.02427379 -0.12153468  0.34320676  0.19601227], Bias = -0.026716629041747843\n",
      "Iteration 927: Weights = [-0.02428815 -0.12152739  0.34321468  0.19603729], Bias = -0.026718126746395485\n",
      "Iteration 928: Weights = [-0.0243025  -0.12152009  0.34322258  0.1960623 ], Bias = -0.026719620881256137\n",
      "Iteration 929: Weights = [-0.02431684 -0.12151277  0.34323045  0.1960873 ], Bias = -0.026721111453591663\n",
      "Iteration 930: Weights = [-0.02433118 -0.12150544  0.34323831  0.19611229], Bias = -0.026722598470648704\n",
      "Iteration 931: Weights = [-0.0243455  -0.12149809  0.34324614  0.19613727], Bias = -0.026724081939658705\n",
      "Iteration 932: Weights = [-0.02435981 -0.12149073  0.34325395  0.19616224], Bias = -0.026725561867837953\n",
      "Iteration 933: Weights = [-0.02437412 -0.12148335  0.34326174  0.19618719], Bias = -0.026727038262387603\n",
      "Iteration 934: Weights = [-0.02438841 -0.12147596  0.34326951  0.19621213], Bias = -0.026728511130493716\n",
      "Iteration 935: Weights = [-0.0244027  -0.12146856  0.34327726  0.19623707], Bias = -0.026729980479327283\n",
      "Iteration 936: Weights = [-0.02441698 -0.12146114  0.34328498  0.19626199], Bias = -0.02673144631604426\n",
      "Iteration 937: Weights = [-0.02443124 -0.12145371  0.34329268  0.1962869 ], Bias = -0.026732908647785603\n",
      "Iteration 938: Weights = [-0.0244455  -0.12144626  0.34330037  0.19631179], Bias = -0.026734367481677294\n",
      "Iteration 939: Weights = [-0.02445975 -0.1214388   0.34330803  0.19633668], Bias = -0.026735822824830377\n",
      "Iteration 940: Weights = [-0.02447399 -0.12143132  0.34331567  0.19636156], Bias = -0.026737274684340985\n",
      "Iteration 941: Weights = [-0.02448822 -0.12142383  0.34332329  0.19638642], Bias = -0.026738723067290377\n",
      "Iteration 942: Weights = [-0.02450245 -0.12141632  0.34333088  0.19641127], Bias = -0.026740167980744963\n",
      "Iteration 943: Weights = [-0.02451666 -0.12140881  0.34333846  0.19643611], Bias = -0.02674160943175634\n",
      "Iteration 944: Weights = [-0.02453087 -0.12140127  0.34334602  0.19646094], Bias = -0.026743047427361315\n",
      "Iteration 945: Weights = [-0.02454506 -0.12139372  0.34335355  0.19648576], Bias = -0.026744481974581954\n",
      "Iteration 946: Weights = [-0.02455925 -0.12138616  0.34336106  0.19651057], Bias = -0.026745913080425593\n",
      "Iteration 947: Weights = [-0.02457342 -0.12137859  0.34336856  0.19653537], Bias = -0.02674734075188488\n",
      "Iteration 948: Weights = [-0.02458759 -0.121371    0.34337603  0.19656015], Bias = -0.026748764995937795\n",
      "Iteration 949: Weights = [-0.02460175 -0.12136339  0.34338348  0.19658493], Bias = -0.0267501858195477\n",
      "Iteration 950: Weights = [-0.0246159  -0.12135577  0.34339091  0.19660969], Bias = -0.026751603229663353\n",
      "Iteration 951: Weights = [-0.02463005 -0.12134814  0.34339832  0.19663444], Bias = -0.026753017233218945\n",
      "Iteration 952: Weights = [-0.02464418 -0.1213405   0.34340571  0.19665919], Bias = -0.02675442783713413\n",
      "Iteration 953: Weights = [-0.0246583  -0.12133284  0.34341307  0.19668392], Bias = -0.026755835048314053\n",
      "Iteration 954: Weights = [-0.02467242 -0.12132516  0.34342042  0.19670864], Bias = -0.02675723887364938\n",
      "Iteration 955: Weights = [-0.02468653 -0.12131748  0.34342775  0.19673334], Bias = -0.026758639320016344\n",
      "Iteration 956: Weights = [-0.02470062 -0.12130977  0.34343505  0.19675804], Bias = -0.026760036394276748\n",
      "Iteration 957: Weights = [-0.02471471 -0.12130206  0.34344234  0.19678273], Bias = -0.026761430103278014\n",
      "Iteration 958: Weights = [-0.02472879 -0.12129433  0.34344961  0.1968074 ], Bias = -0.026762820453853208\n",
      "Iteration 959: Weights = [-0.02474286 -0.12128659  0.34345685  0.19683207], Bias = -0.026764207452821077\n",
      "Iteration 960: Weights = [-0.02475693 -0.12127883  0.34346407  0.19685672], Bias = -0.026765591106986068\n",
      "Iteration 961: Weights = [-0.02477098 -0.12127106  0.34347128  0.19688137], Bias = -0.026766971423138358\n",
      "Iteration 962: Weights = [-0.02478502 -0.12126328  0.34347846  0.196906  ], Bias = -0.0267683484080539\n",
      "Iteration 963: Weights = [-0.02479906 -0.12125548  0.34348563  0.19693062], Bias = -0.026769722068494435\n",
      "Iteration 964: Weights = [-0.02481309 -0.12124767  0.34349277  0.19695523], Bias = -0.02677109241120753\n",
      "Iteration 965: Weights = [-0.02482711 -0.12123985  0.34349989  0.19697983], Bias = -0.026772459442926604\n",
      "Iteration 966: Weights = [-0.02484112 -0.12123201  0.343507    0.19700442], Bias = -0.026773823170370963\n",
      "Iteration 967: Weights = [-0.02485512 -0.12122416  0.34351408  0.197029  ], Bias = -0.026775183600245826\n",
      "Iteration 968: Weights = [-0.02486911 -0.12121629  0.34352114  0.19705356], Bias = -0.026776540739242356\n",
      "Iteration 969: Weights = [-0.0248831  -0.12120841  0.34352818  0.19707812], Bias = -0.026777894594037687\n",
      "Iteration 970: Weights = [-0.02489707 -0.12120052  0.34353521  0.19710267], Bias = -0.026779245171294958\n",
      "Iteration 971: Weights = [-0.02491104 -0.12119262  0.34354221  0.1971272 ], Bias = -0.026780592477663335\n",
      "Iteration 972: Weights = [-0.024925   -0.1211847   0.34354919  0.19715173], Bias = -0.02678193651977805\n",
      "Iteration 973: Weights = [-0.02493895 -0.12117677  0.34355616  0.19717624], Bias = -0.026783277304260424\n",
      "Iteration 974: Weights = [-0.02495289 -0.12116882  0.3435631   0.19720075], Bias = -0.026784614837717897\n",
      "Iteration 975: Weights = [-0.02496683 -0.12116087  0.34357002  0.19722524], Bias = -0.026785949126744056\n",
      "Iteration 976: Weights = [-0.02498075 -0.1211529   0.34357693  0.19724972], Bias = -0.026787280177918666\n",
      "Iteration 977: Weights = [-0.02499467 -0.12114491  0.34358381  0.1972742 ], Bias = -0.0267886079978077\n",
      "Iteration 978: Weights = [-0.02500858 -0.12113691  0.34359068  0.19729866], Bias = -0.026789932592963365\n",
      "Iteration 979: Weights = [-0.02502248 -0.1211289   0.34359752  0.19732311], Bias = -0.026791253969924135\n",
      "Iteration 980: Weights = [-0.02503637 -0.12112088  0.34360435  0.19734755], Bias = -0.026792572135214774\n",
      "Iteration 981: Weights = [-0.02505025 -0.12111284  0.34361116  0.19737198], Bias = -0.026793887095346372\n",
      "Iteration 982: Weights = [-0.02506412 -0.12110479  0.34361794  0.1973964 ], Bias = -0.026795198856816367\n",
      "Iteration 983: Weights = [-0.02507799 -0.12109673  0.34362471  0.19742081], Bias = -0.026796507426108576\n",
      "Iteration 984: Weights = [-0.02509185 -0.12108866  0.34363146  0.19744521], Bias = -0.026797812809693226\n",
      "Iteration 985: Weights = [-0.0251057  -0.12108057  0.34363819  0.1974696 ], Bias = -0.026799115014026983\n",
      "Iteration 986: Weights = [-0.02511954 -0.12107247  0.3436449   0.19749397], Bias = -0.02680041404555297\n",
      "Iteration 987: Weights = [-0.02513337 -0.12106435  0.34365159  0.19751834], Bias = -0.02680170991070081\n",
      "Iteration 988: Weights = [-0.02514719 -0.12105623  0.34365826  0.1975427 ], Bias = -0.02680300261588665\n",
      "Iteration 989: Weights = [-0.02516101 -0.12104809  0.34366491  0.19756705], Bias = -0.02680429216751318\n",
      "Iteration 990: Weights = [-0.02517482 -0.12103993  0.34367154  0.19759139], Bias = -0.026805578571969673\n",
      "Iteration 991: Weights = [-0.02518862 -0.12103177  0.34367816  0.19761571], Bias = -0.026806861835632006\n",
      "Iteration 992: Weights = [-0.02520241 -0.12102359  0.34368475  0.19764003], Bias = -0.026808141964862694\n",
      "Iteration 993: Weights = [-0.02521619 -0.1210154   0.34369133  0.19766434], Bias = -0.02680941896601091\n",
      "Iteration 994: Weights = [-0.02522997 -0.1210072   0.34369788  0.19768863], Bias = -0.026810692845412525\n",
      "Iteration 995: Weights = [-0.02524373 -0.12099898  0.34370442  0.19771292], Bias = -0.02681196360939012\n",
      "Iteration 996: Weights = [-0.02525749 -0.12099075  0.34371094  0.19773719], Bias = -0.026813231264253026\n",
      "Iteration 997: Weights = [-0.02527124 -0.12098251  0.34371744  0.19776146], Bias = -0.026814495816297353\n",
      "Iteration 998: Weights = [-0.02528498 -0.12097426  0.34372392  0.19778571], Bias = -0.026815757271806007\n",
      "Iteration 999: Weights = [-0.02529872 -0.12096599  0.34373038  0.19780996], Bias = -0.02681701563704873\n",
      "Iteration 1000: Weights = [-0.02531244 -0.12095771  0.34373683  0.1978342 ], Bias = -0.026818270918282112\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "for i in range(n_iter):\n",
    "    # Predictions (y_pred) for the current weights and bias\n",
    "    y_pred = np.dot(X_train, w) + b # the equation is: y_pred = X_train * w + b\n",
    "\n",
    "    # Calculate error\n",
    "    error = y_pred - y_train  \n",
    "\n",
    "    # Compute the loss Function (Mean Squared Error)\n",
    "    loss = np.mean((y_pred - y_train) ** 2) \n",
    "\n",
    "    # Compute the gradients\n",
    "    dj_dw = np.mean(error.reshape(-1, 1) * X_train, axis=0)  # Gradient for weights\n",
    "    dj_db = np.mean(error)  # Gradient for bias\n",
    "    \n",
    "    # Update weights and bias\n",
    "    w = w - alpha * dj_dw\n",
    "    b = b - alpha * dj_db\n",
    "\n",
    "    print(f\"Iteration {i+1}: Weights = {w}, Bias = {b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11554f4-6719-4b5a-baf6-9cdba9804ec4",
   "metadata": {},
   "source": [
    "## **--------------------------- Gradient Descent (Scikit Learn) --------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84d591ee-f62e-4a26-8ddd-f265fa8e9971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973c3d4-3b09-4d5b-829c-cf8b2c56b59e",
   "metadata": {},
   "source": [
    "## **---------------------------- Making Predictions (manual) -----------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0a61621-9795-45d1-8932-a4c6f8d97a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.49558344,  1.55055346,  1.38725822,  1.73618418,  1.70553835,\n",
       "        0.04428731,  1.42288968,  1.37227128,  1.98382374,  1.7259832 ,\n",
       "        1.10768965,  1.58495309,  2.04154227,  1.92561425,  1.51096913,\n",
       "        1.34945388,  1.17045043, -0.03887862,  1.95950541,  1.09291142,\n",
       "       -0.06644228, -0.1062829 ,  1.85845252,  0.01366425, -0.0759389 ,\n",
       "        1.94432843, -0.15604544,  1.36659678, -0.02615944,  1.00592922,\n",
       "        1.39374888, -0.00333619,  1.5306133 , -0.07281326,  1.36409551,\n",
       "        1.95585229, -0.0764039 ,  1.17510766,  1.34370728,  2.1628272 ,\n",
       "        0.00743573,  1.23174587,  0.00791765,  1.20315909,  0.0212612 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = np.dot(X_test, w) + b\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08007480-3b11-4582-97fa-e9b2589987c5",
   "metadata": {},
   "source": [
    "## **-------------------------- Making Predictions (Sckit Learn) --------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb6d3aaf-2f80-415e-817c-f7f3c44437c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.62110469,  1.39088989,  1.27165611,  1.66535425,  1.84404279,\n",
       "        0.0124341 ,  1.28657753,  1.39348321,  1.69230342,  1.41425918,\n",
       "        0.90750047,  1.42799636,  2.20148393,  1.88759306,  1.6129916 ,\n",
       "        1.33159581,  1.15543385, -0.10014935,  1.7702428 ,  0.98473274,\n",
       "       -0.08354825,  0.02687839,  1.64917917,  0.05711236,  0.00453536,\n",
       "        1.73376107, -0.13612526,  1.29533099,  0.00711561,  1.08479824,\n",
       "        1.39433268,  0.09541613,  1.59332006, -0.07017559,  1.27873771,\n",
       "        2.20631748, -0.06254487,  1.25758941,  1.25366425,  1.86846539,\n",
       "        0.07252397,  1.17986695, -0.0208192 ,  1.17405826, -0.00485847])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bdbcc-b4ed-4fe1-95cb-6f34a5878327",
   "metadata": {},
   "source": [
    "# **---------------------------- Evaluating the Model (manual) ---------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb88f9e5-7146-4453-874e-28b2b3f5aa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2139955882097475\n",
      "Model Coefficients: [0. 0. 0. 0.]\n",
      "Model Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((y_test - y_pred_test) ** 2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Model Coefficients:\", w)\n",
    "print(\"Model Intercept:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaec249-71f4-412a-8390-c52e21e048d0",
   "metadata": {},
   "source": [
    "## **------------------------- Evaluating the Model (Scikit Learn) ------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e4c4420-5419-4eaa-a7d7-e58e13516c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.06152793419480008\n",
      "Model Coefficients: [-0.10851336 -0.03220617  0.14771246  0.78630854]\n",
      "Model Intercept: 0.2319050344162078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Model Coefficients:\", lr.coef_)\n",
    "print(\"Model Intercept:\", lr.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
